{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/data/codes/prep_ps_pykaldi\n"
     ]
    }
   ],
   "source": [
    "%cd /data/codes/prep_ps_pykaldi/\n",
    "from sklearn.metrics import (\n",
    "    classification_report, \n",
    "    confusion_matrix, \n",
    "    ConfusionMatrixDisplay\n",
    ")\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "import pickle\n",
    "import json\n",
    "import re\n",
    "\n",
    "from torch.utils.data import DataLoader\n",
    "from torch import nn\n",
    "\n",
    "from src.dataset import PrepDataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_score_to_color(score, YELLOW_GREEN=80/50, RED_YELLOW=30/50):\n",
    "    if RED_YELLOW is not None:\n",
    "        LABEL2ID = {\"GREEN\": 0, \"YELLOW\": 1, \"RED\":2}\n",
    "        red_index = score < RED_YELLOW\n",
    "        yellow_index = ((score >= RED_YELLOW).int() & (score < YELLOW_GREEN).int()).bool()\n",
    "        green_index = score >= YELLOW_GREEN\n",
    "    else:\n",
    "        LABEL2ID = {\"GREEN\": 0, \"YELLOW\": 1, \"RED\":1}\n",
    "        RED_YELLOW = 30/50\n",
    "        red_index = score < RED_YELLOW\n",
    "        yellow_index = ((score >= RED_YELLOW).int() & (score < YELLOW_GREEN).int()).bool()\n",
    "        green_index = score >= YELLOW_GREEN\n",
    "\n",
    "\n",
    "    score[red_index] = LABEL2ID[\"RED\"]\n",
    "    score[yellow_index] = LABEL2ID[\"YELLOW\"]\n",
    "    score[green_index] = LABEL2ID[\"GREEN\"]\n",
    "\n",
    "    return score\n",
    "\n",
    "def load_data(data_dir):\n",
    "    phone_ids = np.load(f'{data_dir}/phone_ids.npy')\n",
    "    word_ids = np.load(f'{data_dir}/word_ids.npy')\n",
    "    \n",
    "    phone_scores = np.load(f'{data_dir}/phone_scores.npy')\n",
    "    word_scores = np.load(f'{data_dir}/word_scores.npy')\n",
    "    sentence_scores = np.load(f'{data_dir}/sentence_scores.npy')\n",
    "\n",
    "    durations = np.load(f'{data_dir}/duration.npy')\n",
    "    gops = np.load(f'{data_dir}/gop.npy')\n",
    "    wavlm_features = np.load(f'{data_dir}/wavlm_features.npy')\n",
    "\n",
    "    return phone_ids, word_ids, phone_scores, word_scores, sentence_scores, durations, gops, wavlm_features\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.optim import Adam\n",
    "from src.model import GOPT\n",
    "\n",
    "train_dir = \"/data/codes/prep_ps_pykaldi/exp/sm/train\"\n",
    "\n",
    "phone_ids, word_ids, phone_scores, word_scores, \\\n",
    "    sentence_scores, durations, gops, wavlm_features = load_data(train_dir)\n",
    "trainset = PrepDataset(\n",
    "    phone_ids, word_ids, \n",
    "    phone_scores, word_scores, sentence_scores, \n",
    "    durations, gops, wavlm_features\n",
    "    )\n",
    "\n",
    "trainloader = DataLoader(trainset, batch_size=8, shuffle=True, drop_last=False)\n",
    "\n",
    "test_dir = \"/data/codes/prep_ps_pykaldi/exp/sm/test\"\n",
    "phone_ids, word_ids, phone_scores, word_scores, \\\n",
    "    sentence_scores, durations, gops, wavlm_features = load_data(test_dir)\n",
    "testset = PrepDataset(\n",
    "    phone_ids, word_ids, \n",
    "    phone_scores, word_scores, sentence_scores, \n",
    "    durations, gops, wavlm_features\n",
    "    )\n",
    "\n",
    "testloader = DataLoader(testset, batch_size=8, shuffle=False, drop_last=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "embed_dim=32\n",
    "num_heads=1\n",
    "depth=3\n",
    "input_dim=851\n",
    "num_phone=62\n",
    "max_length=128\n",
    "\n",
    "lr=3e-4\n",
    "weight_decay=5e-7\n",
    "betas=(0.95, 0.999)\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "gopt_model = GOPT(\n",
    "    embed_dim=embed_dim, num_heads=num_heads, \n",
    "    depth=depth, input_dim=input_dim, \n",
    "    max_length=max_length, num_phone=num_phone).to(device)\n",
    "\n",
    "trainables = [p for p in gopt_model.parameters() if p.requires_grad]\n",
    "\n",
    "optimizer = torch.optim.Adam(\n",
    "    trainables, lr, \n",
    "    weight_decay=weight_decay, \n",
    "    betas=betas\n",
    ")\n",
    "\n",
    "loss_fn = nn.MSELoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def valid_phn(predict, target):\n",
    "    preds, targs = [], []\n",
    "\n",
    "    for i in range(predict.shape[0]):\n",
    "        for j in range(predict.shape[1]):\n",
    "            if target[i, j] >= 0:\n",
    "                preds.append(predict[i, j])\n",
    "                targs.append(target[i, j])\n",
    "    targs = np.array(targs)\n",
    "    preds = np.array(preds)\n",
    "\n",
    "    mse = np.mean((targs - preds) ** 2)\n",
    "    mae = np.mean(np.abs(targs - preds))\n",
    "    corr = np.corrcoef(preds, targs)[0, 1]\n",
    "    return mse, mae, corr\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def valid_wrd(predict, target, word_id):\n",
    "    preds, targs = [], []\n",
    "\n",
    "    for i in range(target.shape[0]):\n",
    "        prev_w_id, start_id = 0, 0\n",
    "        # for each token\n",
    "        for j in range(target.shape[1]):\n",
    "            cur_w_id = word_id[i, j].int()\n",
    "            # if a new word\n",
    "            if cur_w_id != prev_w_id:\n",
    "                # average each phone belongs to the word\n",
    "                preds.append(np.mean(predict[i, start_id: j].numpy(), axis=0))\n",
    "                targs.append(np.mean(target[i, start_id: j].numpy(), axis=0))\n",
    "\n",
    "                if cur_w_id == -1:\n",
    "                    break\n",
    "                else:\n",
    "                    prev_w_id = cur_w_id\n",
    "                    start_id = j\n",
    "\n",
    "    preds = np.array(preds)\n",
    "    targs = np.array(targs).round(2)\n",
    "\n",
    "    word_mse = np.mean((preds - targs) ** 2)\n",
    "    wrd_mae = np.mean(np.abs(preds - targs))\n",
    "    word_corr = np.corrcoef(preds, targs)[0, 1]\n",
    "    \n",
    "    return word_mse, wrd_mae, word_corr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def valid_utt(predict, target):\n",
    "    utt_mse = np.mean(((predict[:, 0] - target[:, 0]) ** 2).numpy())\n",
    "    utt_mae = np.mean((np.abs(predict[:, 0] - target[:, 0])).numpy())\n",
    "    \n",
    "    utt_corr = np.corrcoef(predict[:, 0], target[:, 0])[0, 1]\n",
    "    return utt_mse, utt_mae, utt_corr\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_device(batch, device):\n",
    "    features = batch[\"features\"].to(device)\n",
    "    phone_ids = batch[\"phone_ids\"].to(device)\n",
    "    word_ids = batch[\"word_ids\"]\n",
    "    \n",
    "    phone_labels = batch[\"phone_scores\"].to(device)\n",
    "    word_labels = batch[\"word_scores\"].to(device)\n",
    "    utterance_labels = batch[\"sentence_scores\"].to(device)\n",
    "\n",
    "    return features, phone_ids, word_ids, phone_labels, word_labels, utterance_labels\n",
    "\n",
    "def to_cpu(preds, labels):\n",
    "    preds = preds.detach().cpu().squeeze(-1)\n",
    "    labels = labels.detach().cpu()\n",
    "\n",
    "    return preds, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_pred_and_label(pred_path, label_path):\n",
    "    pred = np.load(pred_path)\n",
    "    label = np.load(label_path)\n",
    "\n",
    "    pred = np.concatenate(pred)\n",
    "    label = np.concatenate(label)\n",
    "    index = label != -1    \n",
    "    \n",
    "    return label[index], pred[index]\n",
    "\n",
    "def save_confusion_matrix_figure(\n",
    "        fig_path, pred_path, label_path, YELLOW_GREEN=70/50, RED_YELLOW=35/50):\n",
    "    \n",
    "    label, pred = load_pred_and_label(pred_path=pred_path, label_path=label_path)\n",
    "    \n",
    "    actual = convert_score_to_color(\n",
    "        torch.from_numpy(label), YELLOW_GREEN=YELLOW_GREEN, RED_YELLOW=RED_YELLOW)\n",
    "    \n",
    "    predicted = convert_score_to_color(\n",
    "        torch.from_numpy(pred), YELLOW_GREEN=YELLOW_GREEN, RED_YELLOW=RED_YELLOW)\n",
    "    \n",
    "    cfs_mtr = confusion_matrix(actual, predicted)\n",
    "    cfs_mtr = cfs_mtr / cfs_mtr.sum(axis=1, keepdims=True)\n",
    "    if RED_YELLOW is not None:\n",
    "        cm_display = ConfusionMatrixDisplay(\n",
    "            confusion_matrix = cfs_mtr, display_labels = [\"GREEN\", \"YELLOW\", \"RED\"])\n",
    "    else:\n",
    "        cm_display = ConfusionMatrixDisplay(\n",
    "            confusion_matrix = cfs_mtr, display_labels = [\"CORRECT\", \"INCORRECT\"])\n",
    "\n",
    "    plt.title(\"Confusion Matrix\")\n",
    "    cm_display.plot(cmap='Blues')\n",
    "    plt.savefig(fig_path) \n",
    "\n",
    "def save(epoch, output_dir, model, optimizer, phone_desicion_result, \\\n",
    "    phone_predicts, phone_labels, word_predicts, word_labels, utterance_predicts, utterance_labels):\n",
    "    \n",
    "    model_path = f'{output_dir}/model.pt'\n",
    "    optimizer_path = f'{output_dir}/optimizer.pt'\n",
    "    phone_desicion_result_path = f'{output_dir}/phone_result'\n",
    "\n",
    "    phone_predict_path = f'{output_dir}/phn_pred.npy'\n",
    "    phone_label_path = f'{output_dir}/phn_label.npy'\n",
    "    word_predict_path = f'{output_dir}/wrd_pred.npy'\n",
    "    word_label_path = f'{output_dir}/wrd_label.npy'\n",
    "    utterance_predict_path = f'{output_dir}/utt_pred.npy'\n",
    "    utterance_label_path = f'{output_dir}/utt_label.npy'\n",
    "\n",
    "    three_class_fig_path = f'{output_dir}/confusion_matrix_three_class.png'\n",
    "    two_class_fig_path = f'{output_dir}/confusion_matrix_two_class.png'\n",
    "\n",
    "    with open(phone_desicion_result_path, \"w\") as f:\n",
    "        f.write(phone_desicion_result)\n",
    "\n",
    "    torch.save(model.state_dict(), model_path)\n",
    "    torch.save(optimizer.state_dict(), optimizer_path)\n",
    "    np.save(phone_predict_path, phone_predicts)\n",
    "    np.save(phone_label_path, phone_labels)\n",
    "    np.save(word_predict_path, word_predicts)\n",
    "    np.save(word_label_path, word_labels)\n",
    "    np.save(utterance_predict_path, utterance_predicts)\n",
    "    np.save(utterance_label_path, utterance_labels)\n",
    "    save_confusion_matrix_figure(three_class_fig_path, phone_predict_path, phone_label_path, YELLOW_GREEN=85/50, RED_YELLOW=35/50)\n",
    "    save_confusion_matrix_figure(two_class_fig_path, phone_predict_path, phone_label_path, YELLOW_GREEN=85/50, RED_YELLOW=None)\n",
    "\n",
    "    print(f'Save state dict and result to {output_dir}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "@torch.no_grad()\n",
    "def validate(epoch, gopt_model, testloader, best_mse, ckpt_dir):\n",
    "    gopt_model.eval()\n",
    "    A_phn, A_phn_target = [], []\n",
    "    A_utt, A_utt_target = [], []\n",
    "    A_wrd, A_wrd_target, A_wrd_id = [], [], []\n",
    "\n",
    "    for batch in testloader:\n",
    "        features, phone_ids, word_ids, \\\n",
    "            phone_labels, word_labels, utterance_labels = to_device(batch, device)\n",
    "        \n",
    "        utterance_preds, phone_preds, word_preds = gopt_model(\n",
    "            x=features.float(), phn=phone_ids.long())\n",
    "        \n",
    "        phone_preds, phone_labels = to_cpu(phone_preds, phone_labels)\n",
    "        word_preds, word_labels = to_cpu(word_preds, word_labels)\n",
    "        utterance_preds, utterance_labels = to_cpu(utterance_preds, utterance_labels)\n",
    "        \n",
    "        A_phn.append(phone_preds), A_phn_target.append(phone_labels)\n",
    "        A_utt.append(utterance_preds), A_utt_target.append(utterance_labels)\n",
    "        A_wrd.append(word_preds), A_wrd_target.append(word_labels), A_wrd_id.append(word_ids)\n",
    "    \n",
    "    # phone level\n",
    "    A_phn, A_phn_target  = torch.vstack(A_phn), torch.vstack(A_phn_target)\n",
    "    decision_result = calculate_phone_decision_result(A_phn, A_phn_target)\n",
    "\n",
    "    # word level\n",
    "    A_word, A_word_target, A_word_id = torch.vstack(A_wrd), torch.vstack(A_wrd_target), torch.vstack(A_wrd_id) \n",
    "\n",
    "    # utterance level\n",
    "    A_utt, A_utt_target = torch.vstack(A_utt), torch.vstack(A_utt_target)\n",
    "\n",
    "    # valid_token_mse, mae, corr\n",
    "    phn_mse, phn_mae, phn_corr = valid_phn(A_phn, A_phn_target)\n",
    "    word_mse, wrd_mae, word_corr = valid_wrd(A_word, A_word_target, A_word_id)\n",
    "    utt_mse, utt_mae, utt_corr = valid_utt(A_utt, A_utt_target)\n",
    "\n",
    "    if phn_mse < best_mse:\n",
    "        best_mse = phn_mse\n",
    "        save(\n",
    "            epoch=epoch,\n",
    "            output_dir=ckpt_dir, \n",
    "            model=gopt_model, \n",
    "            optimizer=optimizer, \n",
    "            phone_desicion_result=decision_result, \n",
    "            phone_predicts=A_phn.numpy(), \n",
    "            phone_labels=A_phn_target.numpy(), \n",
    "            word_predicts=A_word.numpy(), \n",
    "            word_labels=A_word_target.numpy(), \n",
    "            utterance_predicts=A_utt.numpy(), \n",
    "            utterance_labels=A_utt_target.numpy()\n",
    "        )\n",
    "\n",
    "    print(f\"### Validation result (epoch={epoch})\")\n",
    "    print(\"  Phone level:  MSE={:.3f}  MAE={:.3f}  PCC={:.3f} \".format(phn_mse, phn_mae, phn_corr))\n",
    "    print(\"   Word level:  MSE={:.3f}  MAE={:.3f}  PCC={:.3f} \".format(word_mse, wrd_mae, word_corr))\n",
    "    print(\"    Utt level:  MSE={:.3f}  MAE={:.3f}  PCC={:.3f} \".format(utt_mse, utt_mae, utt_corr))\n",
    "\n",
    "    return {\n",
    "        \"phn_mse\": phn_mse, \n",
    "        \"phn_mae\": phn_mae,\n",
    "        \"phn_corr\": phn_corr,\n",
    "        \"word_mse\": word_mse,\n",
    "        \"wrd_mae\": wrd_mae,\n",
    "        \"word_corr\": word_corr,\n",
    "        \"utt_mse\": utt_mse,\n",
    "        \"utt_mae\": utt_mae,\n",
    "        \"utt_corr\": utt_corr,\n",
    "        \"best_mse\": best_mse\n",
    "    }\n",
    "\n",
    "def calculate_phone_decision_result(A_phn, A_phn_target):\n",
    "    indices = A_phn_target != -1\n",
    "    _label = A_phn_target[indices].clone()\n",
    "    _pred = A_phn[indices].clone()\n",
    "\n",
    "    converted_pred = convert_score_to_color(_pred).view(-1)\n",
    "    converted_label = convert_score_to_color(_label).view(-1)\n",
    "\n",
    "    result = classification_report(y_true=converted_label, y_pred=converted_pred)\n",
    "    print(\"### F1 Score: \\n\", result)\n",
    "\n",
    "    return result\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_losses(phone_preds, phone_labels, word_preds, word_labels, utterance_preds, utterance_labels):\n",
    "    # phone level\n",
    "    mask = phone_labels >=0\n",
    "    phone_preds = phone_preds.squeeze(2) * mask\n",
    "    phone_labels = phone_labels * mask\n",
    "    \n",
    "    loss_phn = loss_fn(phone_preds, phone_labels)\n",
    "    loss_phn = loss_phn * (mask.shape[0] * mask.shape[1]) / torch.sum(mask)\n",
    "\n",
    "    # utterance level\n",
    "    loss_utt = loss_fn(utterance_preds.squeeze(1) ,utterance_labels)\n",
    "\n",
    "    # word level\n",
    "    mask = word_labels >= 0      \n",
    "    word_preds = word_preds.squeeze(2) * mask\n",
    "    word_labels = word_labels * mask\n",
    "    \n",
    "    loss_word = loss_fn(word_preds, word_labels)\n",
    "    loss_word = loss_word * (mask.shape[0] * mask.shape[1]) / torch.sum(mask)\n",
    "\n",
    "    return loss_phn, loss_utt, loss_word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 18740/18740 [03:42<00:00, 84.14it/s, loss=0.212, loss_phn=0.141, loss_utt=0.0263, loss_word=0.0452]    \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "### F1 Score: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.94      0.83      0.88     99093\n",
      "         1.0       0.20      0.51      0.29     10946\n",
      "         2.0       0.74      0.53      0.62     19040\n",
      "\n",
      "    accuracy                           0.76    129079\n",
      "   macro avg       0.63      0.62      0.60    129079\n",
      "weighted avg       0.85      0.76      0.79    129079\n",
      "\n",
      "Save state dict and result to /data/codes/prep_ps_pykaldi/exp/ckpts\n",
      "### Validation result (epoch=0)\n",
      "  Phone level:  MSE=0.189  MAE=0.255  PCC=0.750 \n",
      "   Word level:  MSE=0.082  MAE=0.211  PCC=0.692 \n",
      "    Utt level:  MSE=0.067  MAE=0.188  PCC=0.719 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 18740/18740 [03:42<00:00, 84.12it/s, loss=0.237, loss_phn=0.129, loss_utt=0.0407, loss_word=0.0673]    \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "### F1 Score: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.95      0.81      0.88     99093\n",
      "         1.0       0.21      0.55      0.30     10946\n",
      "         2.0       0.73      0.57      0.64     19040\n",
      "\n",
      "    accuracy                           0.75    129079\n",
      "   macro avg       0.63      0.65      0.61    129079\n",
      "weighted avg       0.85      0.75      0.79    129079\n",
      "\n",
      "Save state dict and result to /data/codes/prep_ps_pykaldi/exp/ckpts\n",
      "### Validation result (epoch=1)\n",
      "  Phone level:  MSE=0.181  MAE=0.255  PCC=0.764 \n",
      "   Word level:  MSE=0.084  MAE=0.217  PCC=0.711 \n",
      "    Utt level:  MSE=0.072  MAE=0.199  PCC=0.732 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 18740/18740 [03:42<00:00, 84.15it/s, loss=0.146, loss_phn=0.0833, loss_utt=0.03, loss_word=0.0331]     \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "### F1 Score: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.95      0.82      0.88     99093\n",
      "         1.0       0.21      0.51      0.30     10946\n",
      "         2.0       0.72      0.61      0.66     19040\n",
      "\n",
      "    accuracy                           0.76    129079\n",
      "   macro avg       0.62      0.65      0.61    129079\n",
      "weighted avg       0.85      0.76      0.80    129079\n",
      "\n",
      "### Validation result (epoch=2)\n",
      "  Phone level:  MSE=0.182  MAE=0.248  PCC=0.771 \n",
      "   Word level:  MSE=0.073  MAE=0.199  PCC=0.732 \n",
      "    Utt level:  MSE=0.065  MAE=0.190  PCC=0.742 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 18740/18740 [02:41<00:00, 115.70it/s, loss=0.174, loss_phn=0.0936, loss_utt=0.0345, loss_word=0.0461]   \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "### F1 Score: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.95      0.82      0.88     99093\n",
      "         1.0       0.21      0.53      0.30     10946\n",
      "         2.0       0.74      0.60      0.66     19040\n",
      "\n",
      "    accuracy                           0.77    129079\n",
      "   macro avg       0.63      0.65      0.62    129079\n",
      "weighted avg       0.86      0.77      0.80    129079\n",
      "\n",
      "Save state dict and result to /data/codes/prep_ps_pykaldi/exp/ckpts\n",
      "### Validation result (epoch=3)\n",
      "  Phone level:  MSE=0.174  MAE=0.243  PCC=0.777 \n",
      "   Word level:  MSE=0.075  MAE=0.206  PCC=0.731 \n",
      "    Utt level:  MSE=0.063  MAE=0.187  PCC=0.746 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 18740/18740 [03:42<00:00, 84.25it/s, loss=0.293, loss_phn=0.197, loss_utt=0.0146, loss_word=0.081]     \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "### F1 Score: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.95      0.83      0.88     99093\n",
      "         1.0       0.21      0.56      0.30     10946\n",
      "         2.0       0.76      0.54      0.63     19040\n",
      "\n",
      "    accuracy                           0.76    129079\n",
      "   macro avg       0.64      0.64      0.61    129079\n",
      "weighted avg       0.86      0.76      0.80    129079\n",
      "\n",
      "### Validation result (epoch=4)\n",
      "  Phone level:  MSE=0.174  MAE=0.248  PCC=0.770 \n",
      "   Word level:  MSE=0.075  MAE=0.205  PCC=0.722 \n",
      "    Utt level:  MSE=0.062  MAE=0.187  PCC=0.748 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 18740/18740 [03:42<00:00, 84.17it/s, loss=0.285, loss_phn=0.147, loss_utt=0.06, loss_word=0.0773]      \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "### F1 Score: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.96      0.80      0.87     99093\n",
      "         1.0       0.21      0.58      0.30     10946\n",
      "         2.0       0.74      0.61      0.67     19040\n",
      "\n",
      "    accuracy                           0.75    129079\n",
      "   macro avg       0.63      0.66      0.61    129079\n",
      "weighted avg       0.86      0.75      0.79    129079\n",
      "\n",
      "Save state dict and result to /data/codes/prep_ps_pykaldi/exp/ckpts\n",
      "### Validation result (epoch=5)\n",
      "  Phone level:  MSE=0.170  MAE=0.249  PCC=0.784 \n",
      "   Word level:  MSE=0.082  MAE=0.226  PCC=0.745 \n",
      "    Utt level:  MSE=0.074  MAE=0.214  PCC=0.759 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 18740/18740 [03:43<00:00, 84.01it/s, loss=0.296, loss_phn=0.137, loss_utt=0.08, loss_word=0.0789]      \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "### F1 Score: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.96      0.78      0.86     99093\n",
      "         1.0       0.20      0.61      0.30     10946\n",
      "         2.0       0.75      0.61      0.67     19040\n",
      "\n",
      "    accuracy                           0.74    129079\n",
      "   macro avg       0.64      0.67      0.61    129079\n",
      "weighted avg       0.87      0.74      0.79    129079\n",
      "\n",
      "Save state dict and result to /data/codes/prep_ps_pykaldi/exp/ckpts\n",
      "### Validation result (epoch=6)\n",
      "  Phone level:  MSE=0.169  MAE=0.261  PCC=0.789 \n",
      "   Word level:  MSE=0.084  MAE=0.228  PCC=0.747 \n",
      "    Utt level:  MSE=0.071  MAE=0.207  PCC=0.762 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 18740/18740 [03:43<00:00, 84.01it/s, loss=0.145, loss_phn=0.0901, loss_utt=0.0196, loss_word=0.035]    \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "### F1 Score: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.95      0.84      0.89     99093\n",
      "         1.0       0.22      0.59      0.32     10946\n",
      "         2.0       0.79      0.53      0.64     19040\n",
      "\n",
      "    accuracy                           0.77    129079\n",
      "   macro avg       0.66      0.65      0.62    129079\n",
      "weighted avg       0.87      0.77      0.80    129079\n",
      "\n",
      "Save state dict and result to /data/codes/prep_ps_pykaldi/exp/ckpts\n",
      "### Validation result (epoch=7)\n",
      "  Phone level:  MSE=0.159  MAE=0.237  PCC=0.791 \n",
      "   Word level:  MSE=0.067  MAE=0.190  PCC=0.753 \n",
      "    Utt level:  MSE=0.056  MAE=0.174  PCC=0.765 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 18740/18740 [03:43<00:00, 83.80it/s, loss=0.22, loss_phn=0.13, loss_utt=0.0472, loss_word=0.043]       \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "### F1 Score: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.96      0.78      0.86     99093\n",
      "         1.0       0.20      0.63      0.30     10946\n",
      "         2.0       0.76      0.59      0.66     19040\n",
      "\n",
      "    accuracy                           0.74    129079\n",
      "   macro avg       0.64      0.66      0.61    129079\n",
      "weighted avg       0.87      0.74      0.79    129079\n",
      "\n",
      "### Validation result (epoch=8)\n",
      "  Phone level:  MSE=0.166  MAE=0.266  PCC=0.789 \n",
      "   Word level:  MSE=0.077  MAE=0.222  PCC=0.757 \n",
      "    Utt level:  MSE=0.067  MAE=0.207  PCC=0.771 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 18740/18740 [03:42<00:00, 84.13it/s, loss=0.441, loss_phn=0.284, loss_utt=0.0506, loss_word=0.107]     \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "### F1 Score: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.95      0.85      0.90     99093\n",
      "         1.0       0.23      0.55      0.32     10946\n",
      "         2.0       0.78      0.56      0.65     19040\n",
      "\n",
      "    accuracy                           0.78    129079\n",
      "   macro avg       0.65      0.65      0.62    129079\n",
      "weighted avg       0.86      0.78      0.81    129079\n",
      "\n",
      "### Validation result (epoch=9)\n",
      "  Phone level:  MSE=0.159  MAE=0.228  PCC=0.793 \n",
      "   Word level:  MSE=0.066  MAE=0.187  PCC=0.759 \n",
      "    Utt level:  MSE=0.055  MAE=0.171  PCC=0.772 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 18740/18740 [03:43<00:00, 83.95it/s, loss=0.136, loss_phn=0.0694, loss_utt=0.0312, loss_word=0.0355]   \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "### F1 Score: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.95      0.83      0.89     99093\n",
      "         1.0       0.22      0.56      0.32     10946\n",
      "         2.0       0.76      0.62      0.68     19040\n",
      "\n",
      "    accuracy                           0.77    129079\n",
      "   macro avg       0.64      0.67      0.63    129079\n",
      "weighted avg       0.86      0.77      0.81    129079\n",
      "\n"
     ]
    }
   ],
   "source": [
    "global_step = 0\n",
    "best_mse = 1e5\n",
    "num_epoch = 50 \n",
    "phone_weight = 1.0\n",
    "word_weight = 1.0\n",
    "utterance_weight = 1.0\n",
    "ckpt_dir = '/data/codes/prep_ps_pykaldi/exp/ckpts'\n",
    "\n",
    "for epoch in range(num_epoch):\n",
    "    gopt_model.train()\n",
    "    train_tqdm = tqdm(trainloader, \"Training\")\n",
    "    for batch in train_tqdm:\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        features, phone_ids, word_ids, \\\n",
    "            phone_labels, word_labels, utterance_labels = to_device(batch, device)\n",
    "\n",
    "        utterance_preds, phone_preds, word_preds = gopt_model(\n",
    "            x=features.float(), phn=phone_ids.long())\n",
    "        \n",
    "        loss_phn, loss_utt, loss_word = calculate_losses(\n",
    "            phone_preds=phone_preds, \n",
    "            phone_labels=phone_labels, \n",
    "            word_preds=word_preds, \n",
    "            word_labels=word_labels, \n",
    "            utterance_preds=utterance_preds, \n",
    "            utterance_labels=utterance_labels)\n",
    "\n",
    "        # total loss\n",
    "        loss = phone_weight*loss_phn + word_weight*loss_word + utterance_weight*loss_utt\n",
    "        \n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        global_step += 1\n",
    "        train_tqdm.set_postfix(\n",
    "            loss=loss.item(), \n",
    "            loss_phn=loss_phn.item(), \n",
    "            loss_word=loss_word.item(), \n",
    "            loss_utt=loss_utt.item())\n",
    "    \n",
    "    valid_result = validate(\n",
    "        epoch=epoch, \n",
    "        gopt_model=gopt_model, \n",
    "        testloader=testloader, \n",
    "        best_mse=best_mse, \n",
    "        ckpt_dir=ckpt_dir)\n",
    "    \n",
    "    best_mse = valid_result[\"best_mse\"]\n",
    "    \n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ps",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.17"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
