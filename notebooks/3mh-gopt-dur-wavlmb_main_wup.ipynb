{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%cd /data/codes/prep_ps_pykaldi/\n",
    "from sklearn.metrics import (\n",
    "    classification_report, \n",
    "    confusion_matrix, \n",
    "    ConfusionMatrixDisplay\n",
    ")\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "import pickle\n",
    "import json\n",
    "import re\n",
    "\n",
    "from torch.utils.data import DataLoader\n",
    "from torch import nn\n",
    "\n",
    "from src.dataset import PrepDataset\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_score_to_color(score, YELLOW_GREEN=80/50, RED_YELLOW=30/50):\n",
    "    if RED_YELLOW is not None:\n",
    "        LABEL2ID = {\"GREEN\": 0, \"YELLOW\": 1, \"RED\":2}\n",
    "        red_index = score < RED_YELLOW\n",
    "        yellow_index = ((score >= RED_YELLOW).int() & (score < YELLOW_GREEN).int()).bool()\n",
    "        green_index = score >= YELLOW_GREEN\n",
    "    else:\n",
    "        LABEL2ID = {\"GREEN\": 0, \"YELLOW\": 1, \"RED\":1}\n",
    "        RED_YELLOW = 30/50\n",
    "        red_index = score < RED_YELLOW\n",
    "        yellow_index = ((score >= RED_YELLOW).int() & (score < YELLOW_GREEN).int()).bool()\n",
    "        green_index = score >= YELLOW_GREEN\n",
    "\n",
    "\n",
    "    score[red_index] = LABEL2ID[\"RED\"]\n",
    "    score[yellow_index] = LABEL2ID[\"YELLOW\"]\n",
    "    score[green_index] = LABEL2ID[\"GREEN\"]\n",
    "\n",
    "    return score\n",
    "\n",
    "def load_data(data_dir):\n",
    "    phone_ids = np.load(f'{data_dir}/phone_ids.npy')\n",
    "    word_ids = np.load(f'{data_dir}/word_ids.npy')\n",
    "    \n",
    "    phone_scores = np.load(f'{data_dir}/phone_scores.npy')\n",
    "    word_scores = np.load(f'{data_dir}/word_scores.npy')\n",
    "    sentence_scores = np.load(f'{data_dir}/sentence_scores.npy')\n",
    "\n",
    "    durations = np.load(f'{data_dir}/duration.npy')\n",
    "    gops = np.load(f'{data_dir}/gop.npy')\n",
    "    wavlm_features = np.load(f'{data_dir}/wavlm_features.npy')\n",
    "\n",
    "    return phone_ids, word_ids, phone_scores, word_scores, sentence_scores, durations, gops, wavlm_features\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.optim import Adam\n",
    "from src.model import GOPT\n",
    "\n",
    "train_dir = \"/data/codes/prep_ps_pykaldi/exp/sm/train_new\"\n",
    "\n",
    "phone_ids, word_ids, phone_scores, word_scores, \\\n",
    "    sentence_scores, durations, gops, wavlm_features = load_data(train_dir)\n",
    "trainset = PrepDataset(\n",
    "    phone_ids, word_ids, \n",
    "    phone_scores, word_scores, sentence_scores, \n",
    "    durations, gops, wavlm_features\n",
    "    )\n",
    "\n",
    "trainloader = DataLoader(trainset, batch_size=8, shuffle=True, drop_last=False)\n",
    "\n",
    "test_dir = \"/data/codes/prep_ps_pykaldi/exp/sm/test\"\n",
    "phone_ids, word_ids, phone_scores, word_scores, \\\n",
    "    sentence_scores, durations, gops, wavlm_features = load_data(test_dir)\n",
    "testset = PrepDataset(\n",
    "    phone_ids, word_ids, \n",
    "    phone_scores, word_scores, sentence_scores, \n",
    "    durations, gops, wavlm_features\n",
    "    )\n",
    "\n",
    "testloader = DataLoader(testset, batch_size=8, shuffle=False, drop_last=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "embed_dim=32\n",
    "num_heads=1\n",
    "depth=3\n",
    "input_dim=851\n",
    "num_phone=42\n",
    "max_length=128\n",
    "\n",
    "lr=1e-3\n",
    "weight_decay=5e-7\n",
    "betas=(0.95, 0.999)\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "gopt_model = GOPT(\n",
    "    embed_dim=embed_dim, num_heads=num_heads, \n",
    "    depth=depth, input_dim=input_dim, \n",
    "    max_length=max_length, num_phone=num_phone, dropout=0.1).to(device)\n",
    "\n",
    "trainables = [p for p in gopt_model.parameters() if p.requires_grad]\n",
    "\n",
    "optimizer = torch.optim.Adam(\n",
    "    trainables, lr, \n",
    "    weight_decay=weight_decay, \n",
    "    betas=betas\n",
    ")\n",
    "\n",
    "loss_fn = nn.MSELoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def valid_phn(predict, target):\n",
    "    preds, targs = [], []\n",
    "\n",
    "    for i in range(predict.shape[0]):\n",
    "        for j in range(predict.shape[1]):\n",
    "            if target[i, j] >= 0:\n",
    "                preds.append(predict[i, j])\n",
    "                targs.append(target[i, j])\n",
    "    targs = np.array(targs)\n",
    "    preds = np.array(preds)\n",
    "\n",
    "    mse = np.mean((targs - preds) ** 2)\n",
    "    mae = np.mean(np.abs(targs - preds))\n",
    "    corr = np.corrcoef(preds, targs)[0, 1]\n",
    "    return mse, mae, corr\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def valid_wrd(predict, target, word_id):\n",
    "    preds, targs = [], []\n",
    "\n",
    "    for i in range(target.shape[0]):\n",
    "        prev_w_id, start_id = 0, 0\n",
    "        # for each token\n",
    "        for j in range(target.shape[1]):\n",
    "            cur_w_id = word_id[i, j].int()\n",
    "            # if a new word\n",
    "            if cur_w_id != prev_w_id:\n",
    "                # average each phone belongs to the word\n",
    "                preds.append(np.mean(predict[i, start_id: j].numpy(), axis=0))\n",
    "                targs.append(np.mean(target[i, start_id: j].numpy(), axis=0))\n",
    "\n",
    "                if cur_w_id == -1:\n",
    "                    break\n",
    "                else:\n",
    "                    prev_w_id = cur_w_id\n",
    "                    start_id = j\n",
    "\n",
    "    preds = np.array(preds)\n",
    "    targs = np.array(targs).round(2)\n",
    "\n",
    "    word_mse = np.mean((preds - targs) ** 2)\n",
    "    wrd_mae = np.mean(np.abs(preds - targs))\n",
    "    word_corr = np.corrcoef(preds, targs)[0, 1]\n",
    "    \n",
    "    return word_mse, wrd_mae, word_corr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def valid_utt(predict, target):\n",
    "    utt_mse = np.mean(((predict[:, 0] - target[:, 0]) ** 2).numpy())\n",
    "    utt_mae = np.mean((np.abs(predict[:, 0] - target[:, 0])).numpy())\n",
    "    \n",
    "    utt_corr = np.corrcoef(predict[:, 0], target[:, 0])[0, 1]\n",
    "    return utt_mse, utt_mae, utt_corr\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_device(batch, device):\n",
    "    features = batch[\"features\"].to(device)\n",
    "    phone_ids = batch[\"phone_ids\"].to(device)\n",
    "    word_ids = batch[\"word_ids\"]\n",
    "    \n",
    "    phone_labels = batch[\"phone_scores\"].to(device)\n",
    "    word_labels = batch[\"word_scores\"].to(device)\n",
    "    utterance_labels = batch[\"sentence_scores\"].to(device)\n",
    "\n",
    "    return features, phone_ids, word_ids, phone_labels, word_labels, utterance_labels\n",
    "\n",
    "def to_cpu(preds, labels):\n",
    "    preds = preds.detach().cpu().squeeze(-1)\n",
    "    labels = labels.detach().cpu()\n",
    "\n",
    "    return preds, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_pred_and_label(pred_path, label_path):\n",
    "    pred = np.load(pred_path)\n",
    "    label = np.load(label_path)\n",
    "\n",
    "    pred = np.concatenate(pred)\n",
    "    label = np.concatenate(label)\n",
    "    index = label != -1    \n",
    "    \n",
    "    return label[index], pred[index]\n",
    "\n",
    "def save_confusion_matrix_figure(\n",
    "        fig_path, pred_path, label_path, YELLOW_GREEN=80/50, RED_YELLOW=30/50):\n",
    "    \n",
    "    label, pred = load_pred_and_label(pred_path=pred_path, label_path=label_path)\n",
    "    \n",
    "    actual = convert_score_to_color(\n",
    "        torch.from_numpy(label), YELLOW_GREEN=YELLOW_GREEN, RED_YELLOW=RED_YELLOW)\n",
    "    \n",
    "    predicted = convert_score_to_color(\n",
    "        torch.from_numpy(pred), YELLOW_GREEN=YELLOW_GREEN, RED_YELLOW=RED_YELLOW)\n",
    "    \n",
    "    cfs_mtr = confusion_matrix(actual, predicted)\n",
    "    cfs_mtr = cfs_mtr / cfs_mtr.sum(axis=1, keepdims=True)\n",
    "    if RED_YELLOW is not None:\n",
    "        cm_display = ConfusionMatrixDisplay(\n",
    "            confusion_matrix = cfs_mtr, display_labels = [\"GREEN\", \"YELLOW\", \"RED\"])\n",
    "    else:\n",
    "        cm_display = ConfusionMatrixDisplay(\n",
    "            confusion_matrix = cfs_mtr, display_labels = [\"CORRECT\", \"INCORRECT\"])\n",
    "\n",
    "    plt.title(\"Confusion Matrix\")\n",
    "    cm_display.plot(cmap='Blues')\n",
    "    plt.savefig(fig_path) \n",
    "    plt.close()\n",
    "\n",
    "def save(epoch, output_dir, model, optimizer, phone_desicion_result, \\\n",
    "    phone_predicts, phone_labels, word_predicts, word_labels, utterance_predicts, utterance_labels):\n",
    "    \n",
    "    model_path = f'{output_dir}/model.pt'\n",
    "    optimizer_path = f'{output_dir}/optimizer.pt'\n",
    "    phone_desicion_result_path = f'{output_dir}/phone_result'\n",
    "\n",
    "    phone_predict_path = f'{output_dir}/phn_pred.npy'\n",
    "    phone_label_path = f'{output_dir}/phn_label.npy'\n",
    "    word_predict_path = f'{output_dir}/wrd_pred.npy'\n",
    "    word_label_path = f'{output_dir}/wrd_label.npy'\n",
    "    utterance_predict_path = f'{output_dir}/utt_pred.npy'\n",
    "    utterance_label_path = f'{output_dir}/utt_label.npy'\n",
    "\n",
    "    three_class_fig_path = f'{output_dir}/confusion_matrix_three_class.png'\n",
    "    two_class_fig_path = f'{output_dir}/confusion_matrix_two_class.png'\n",
    "\n",
    "    with open(phone_desicion_result_path, \"w\") as f:\n",
    "        f.write(phone_desicion_result)\n",
    "\n",
    "    torch.save(model.state_dict(), model_path)\n",
    "    torch.save(optimizer.state_dict(), optimizer_path)\n",
    "    np.save(phone_predict_path, phone_predicts)\n",
    "    np.save(phone_label_path, phone_labels)\n",
    "    np.save(word_predict_path, word_predicts)\n",
    "    np.save(word_label_path, word_labels)\n",
    "    np.save(utterance_predict_path, utterance_predicts)\n",
    "    np.save(utterance_label_path, utterance_labels)\n",
    "    save_confusion_matrix_figure(three_class_fig_path, phone_predict_path, phone_label_path, YELLOW_GREEN=80/50, RED_YELLOW=30/50)\n",
    "    save_confusion_matrix_figure(two_class_fig_path, phone_predict_path, phone_label_path, YELLOW_GREEN=80/50, RED_YELLOW=None)\n",
    "\n",
    "    print(f'Save state dict and result to {output_dir}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@torch.no_grad()\n",
    "def validate(epoch, gopt_model, testloader, best_mse, ckpt_dir):\n",
    "    gopt_model.eval()\n",
    "    A_phn, A_phn_target = [], []\n",
    "    A_utt, A_utt_target = [], []\n",
    "    A_wrd, A_wrd_target, A_wrd_id = [], [], []\n",
    "\n",
    "    for batch in testloader:\n",
    "        features, phone_ids, word_ids, \\\n",
    "            phone_labels, word_labels, utterance_labels = to_device(batch, device)\n",
    "        \n",
    "        utterance_preds, phone_preds, word_preds = gopt_model(\n",
    "            x=features.float(), phn=phone_ids.long())\n",
    "        \n",
    "        phone_preds, phone_labels = to_cpu(phone_preds, phone_labels)\n",
    "        word_preds, word_labels = to_cpu(word_preds, word_labels)\n",
    "        utterance_preds, utterance_labels = to_cpu(utterance_preds, utterance_labels)\n",
    "        \n",
    "        A_phn.append(phone_preds), A_phn_target.append(phone_labels)\n",
    "        A_utt.append(utterance_preds), A_utt_target.append(utterance_labels)\n",
    "        A_wrd.append(word_preds), A_wrd_target.append(word_labels), A_wrd_id.append(word_ids)\n",
    "    \n",
    "    # phone level\n",
    "    A_phn, A_phn_target  = torch.vstack(A_phn), torch.vstack(A_phn_target)\n",
    "    decision_result = calculate_phone_decision_result(A_phn, A_phn_target)\n",
    "\n",
    "    # word level\n",
    "    A_word, A_word_target, A_word_id = torch.vstack(A_wrd), torch.vstack(A_wrd_target), torch.vstack(A_wrd_id) \n",
    "\n",
    "    # utterance level\n",
    "    A_utt, A_utt_target = torch.vstack(A_utt), torch.vstack(A_utt_target)\n",
    "\n",
    "    # valid_token_mse, mae, corr\n",
    "    phn_mse, phn_mae, phn_corr = valid_phn(A_phn, A_phn_target)\n",
    "    word_mse, wrd_mae, word_corr = valid_wrd(A_word, A_word_target, A_word_id)\n",
    "    utt_mse, utt_mae, utt_corr = valid_utt(A_utt, A_utt_target)\n",
    "\n",
    "    if phn_mse < best_mse:\n",
    "        best_mse = phn_mse\n",
    "    ckpt_dir = f'{ckpt_dir}/ckpts-eph={epoch}-mse={round(phn_mse, 4)}'\n",
    "    os.makedirs(ckpt_dir)\n",
    "    \n",
    "    save(\n",
    "        epoch=epoch,\n",
    "        output_dir=ckpt_dir, \n",
    "        model=gopt_model, \n",
    "        optimizer=optimizer, \n",
    "        phone_desicion_result=decision_result, \n",
    "        phone_predicts=A_phn.numpy(), \n",
    "        phone_labels=A_phn_target.numpy(), \n",
    "        word_predicts=A_word.numpy(), \n",
    "        word_labels=A_word_target.numpy(), \n",
    "        utterance_predicts=A_utt.numpy(), \n",
    "        utterance_labels=A_utt_target.numpy()\n",
    "    )\n",
    "\n",
    "    print(f\"### Validation result (epoch={epoch})\")\n",
    "    print(\"  Phone level:  MSE={:.3f}  MAE={:.3f}  PCC={:.3f} \".format(phn_mse, phn_mae, phn_corr))\n",
    "    print(\"   Word level:  MSE={:.3f}  MAE={:.3f}  PCC={:.3f} \".format(word_mse, wrd_mae, word_corr))\n",
    "    print(\"    Utt level:  MSE={:.3f}  MAE={:.3f}  PCC={:.3f} \".format(utt_mse, utt_mae, utt_corr))\n",
    "\n",
    "    return {\n",
    "        \"phn_mse\": phn_mse, \n",
    "        \"phn_mae\": phn_mae,\n",
    "        \"phn_corr\": phn_corr,\n",
    "        \"word_mse\": word_mse,\n",
    "        \"wrd_mae\": wrd_mae,\n",
    "        \"word_corr\": word_corr,\n",
    "        \"utt_mse\": utt_mse,\n",
    "        \"utt_mae\": utt_mae,\n",
    "        \"utt_corr\": utt_corr,\n",
    "        \"best_mse\": best_mse\n",
    "    }\n",
    "\n",
    "def calculate_phone_decision_result(A_phn, A_phn_target):\n",
    "    indices = A_phn_target != -1\n",
    "    _label = A_phn_target[indices].clone()\n",
    "    _pred = A_phn[indices].clone()\n",
    "\n",
    "    converted_pred = convert_score_to_color(_pred).view(-1)\n",
    "    converted_label = convert_score_to_color(_label).view(-1)\n",
    "\n",
    "    result = classification_report(y_true=converted_label, y_pred=converted_pred)\n",
    "    print(\"### F1 Score: \\n\", result)\n",
    "\n",
    "    return result\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_losses(phone_preds, phone_labels, word_preds, word_labels, utterance_preds, utterance_labels):\n",
    "    # phone level\n",
    "    mask = phone_labels >=0\n",
    "    phone_preds = phone_preds.squeeze(2) * mask\n",
    "    phone_labels = phone_labels * mask\n",
    "    \n",
    "    loss_phn = loss_fn(phone_preds, phone_labels)\n",
    "    loss_phn = loss_phn * (mask.shape[0] * mask.shape[1]) / torch.sum(mask)\n",
    "\n",
    "    # utterance level\n",
    "    loss_utt = loss_fn(utterance_preds.squeeze(1) ,utterance_labels)\n",
    "    # loss_utt = torch.tensor(0)\n",
    "\n",
    "    # word level\n",
    "    mask = word_labels >= 0      \n",
    "    word_preds = word_preds.squeeze(2) * mask\n",
    "    word_labels = word_labels * mask\n",
    "    \n",
    "    loss_word = loss_fn(word_preds, word_labels)\n",
    "    loss_word = loss_word * (mask.shape[0] * mask.shape[1]) / torch.sum(mask)\n",
    "    # loss_word = torch.tensor(0)\n",
    "\n",
    "    return loss_phn, loss_utt, loss_word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "global_step = 0\n",
    "best_mse = 1e5\n",
    "num_epoch = 50 \n",
    "phone_weight = 1.0\n",
    "word_weight = 1.0\n",
    "utterance_weight = 1.0\n",
    "ckpt_dir = '/data/codes/prep_ps_pykaldi/exp/ckpts/in_long_old'\n",
    "\n",
    "for epoch in range(num_epoch):\n",
    "    gopt_model.train()\n",
    "    train_tqdm = tqdm(trainloader, \"Training\")\n",
    "    for batch in train_tqdm:\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        features, phone_ids, word_ids, \\\n",
    "            phone_labels, word_labels, utterance_labels = to_device(batch, device)\n",
    "\n",
    "        utterance_preds, phone_preds, word_preds = gopt_model(\n",
    "            x=features.float(), phn=phone_ids.long())\n",
    "        \n",
    "        loss_phn, loss_utt, loss_word = calculate_losses(\n",
    "            phone_preds=phone_preds, \n",
    "            phone_labels=phone_labels, \n",
    "            word_preds=word_preds, \n",
    "            word_labels=word_labels, \n",
    "            utterance_preds=utterance_preds, \n",
    "            utterance_labels=utterance_labels)\n",
    "\n",
    "        # total loss\n",
    "        loss = phone_weight*loss_phn + word_weight*loss_word + utterance_weight*loss_utt\n",
    "        \n",
    "        loss.backward()\n",
    "        torch.nn.utils.clip_grad_norm_(gopt_model.parameters(), 1.0)\n",
    "        \n",
    "        optimizer.step()\n",
    "        \n",
    "        global_step += 1\n",
    "        train_tqdm.set_postfix(\n",
    "            loss=loss.item(), \n",
    "            loss_phn=loss_phn.item(), \n",
    "            loss_word=loss_word.item(), \n",
    "            loss_utt=loss_utt.item())\n",
    "    \n",
    "    valid_result = validate(\n",
    "        epoch=epoch, \n",
    "        gopt_model=gopt_model, \n",
    "        testloader=testloader, \n",
    "        best_mse=best_mse, \n",
    "        ckpt_dir=ckpt_dir)\n",
    "    \n",
    "    best_mse = valid_result[\"best_mse\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ps",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.17"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
