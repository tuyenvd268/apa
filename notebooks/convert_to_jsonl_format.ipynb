{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import librosa\n",
    "import pickle\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = \"/data/codes/prep_ps_pykaldi/prep_data/raw/info_in_domain_long_sentence_testset_old.csv\"\n",
    "metadata = pd.read_csv(path, index_col=0)\n",
    "metadata[\"score\"] = metadata.score.apply(lambda x: json.loads(x))\n",
    "metadata.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wav_dir = \"/data/codes/prep_ps_pykaldi/prep_data/wav\"\n",
    "def is_valid(id):\n",
    "    wav_path = f'{wav_dir}/{id}.wav'\n",
    "    \n",
    "    try:\n",
    "        librosa.load(wav_path, sr=16000)\n",
    "        return True\n",
    "    except:\n",
    "        return False\n",
    "    \n",
    "temp = metadata.id.apply(is_valid)\n",
    "metadata = metadata[temp==True]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metadata[\"word_ids\"] = None\n",
    "for index in metadata.index:\n",
    "    word_ids = []\n",
    "    for word_id, word in enumerate(metadata[\"score\"][index][\"phonemes\"]):\n",
    "        expanded_phone = []\n",
    "        for phone in word:\n",
    "            if len(phone[\"trans\"].split()) > 1:\n",
    "                cpy_phone = phone.copy()\n",
    "                for trans, arpa in zip(phone[\"trans\"].split(), phone[\"arpa\"].split()):\n",
    "                    cpy_phone[\"trans\"] = trans\n",
    "                    cpy_phone[\"arpa\"] = arpa\n",
    "                    expanded_phone.append(cpy_phone.copy())\n",
    "            else:\n",
    "                expanded_phone.append(phone)\n",
    "            word_ids.append(word_id)\n",
    "        metadata.loc[index, \"score\"][\"phonemes\"][word_id] = expanded_phone\n",
    "        \n",
    "    metadata[\"word_ids\"][index] = word_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = []\n",
    "for index in metadata.index:\n",
    "    user_id = str(metadata[\"user_id\"][index])\n",
    "    wav_id = str(metadata[\"id\"][index])\n",
    "    mark_metadata = metadata[\"score\"][index]\n",
    "    text = metadata[\"question_content\"][index]\n",
    "    question_id = str(metadata[\"question_id\"][index])\n",
    "        \n",
    "    arpas = [word[\"arpa\"] for word in mark_metadata[\"words\"]] \n",
    "    arpas = \" \".join(arpas).split()\n",
    "    trans = [word[\"trans\"] for sample in mark_metadata[\"phonemes\"] for word in sample] \n",
    "    phone_scores = [int(phone[\"score\"]) for word in mark_metadata[\"phonemes\"] for phone in word] \n",
    "    word_ids = metadata[\"word_ids\"][index]\n",
    "    word_scores = [int(word[\"score\"]) for word in mark_metadata[\"words\"]]\n",
    "    utterance_score = mark_metadata[\"utterance\"]\n",
    "\n",
    "    sample = {\n",
    "        \"uid\": user_id,\n",
    "        \"id\": wav_id,\n",
    "        \"qid\":question_id,\n",
    "        \"text\": text,\n",
    "        \"arpas\":arpas,\n",
    "        \"phone_scores\":phone_scores,\n",
    "        \"word_ids\": word_ids,\n",
    "        \"trans\":trans,\n",
    "        \"word_scores\":word_scores,\n",
    "        \"utterance_scores\": utterance_score\n",
    "    }\n",
    "    \n",
    "    data.append(sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = \"/data/codes/prep_ps_pykaldi/prep_data/jsonl_v1/info_in_domain_long_sentence_testset_old.jsonl\"\n",
    "with open(path, \"w\", encoding=\"utf-8\") as f:\n",
    "    for line in data:\n",
    "        json_obj = json.dumps(line)\n",
    "        f.write(f'{json_obj}\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prepare data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = \"/data/codes/prep_ps_pykaldi/prep_data/jsonl_v1/info_in_domain_long_sentence_testset_old.jsonl\"\n",
    "with open(path, \"r\", encoding=\"utf-8\") as f:\n",
    "    lines = [json.loads(line.strip()) for line in f.readlines()]\n",
    "\n",
    "df = pd.DataFrame(lines)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[[\"id\", \"text\"]].to_csv(\"/data/codes/prep_ps_pykaldi/prep_data/info_in_domain_long_sentence_testset_old.csv\", sep=\"|\", index=None, header=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Copy audio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import torchaudio\n",
    "import librosa\n",
    "import shutil\n",
    "import json\n",
    "import os\n",
    "\n",
    "from pandarallel import pandarallel\n",
    "pandarallel.initialize(nb_workers=8, progress_bar=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "audio_dir = \"/data/codes/prep_ps_pykaldi/prep_data/wav\"\n",
    "audio_files = os.listdir(audio_dir)\n",
    "audio_files = [audio_file.split(\".\")[0] for audio_file in audio_files]\n",
    "audio_files = set(audio_files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = \"/data/codes/prep_ps_pykaldi/prep_data/info_in_domain_long_sentence_testset.csv\"\n",
    "df = pd.read_csv(path, names=[\"id\", \"text\"], sep=\"|\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.id.parallel_apply(lambda x: str(x) in audio_files).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "in_dir = \"/data/audio_data/prep_submission_audio/10\"\n",
    "out_dir = audio_dir\n",
    "\n",
    "def copy_audio(id):\n",
    "    path = f'{in_dir}/{id}.wav'\n",
    "    wav, sr = torchaudio.load(path)\n",
    "    if sr == 8000:\n",
    "        return False\n",
    "    # shutil.copy(src=path, dst=out_dir)\n",
    "    return True\n",
    "    \n",
    "\n",
    "is_success = df.id.parallel_apply(copy_audio)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[~is_success]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ps",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.17"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
