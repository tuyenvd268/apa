{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%cd /data/codes/prep_ps_pykaldi/\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pickle\n",
    "import json\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(data_dir):\n",
    "    phone_ids = np.load(f'{data_dir}/phone_ids.npy')\n",
    "    phone_scores = np.load(f'{data_dir}/phone_scores.npy')\n",
    "    durations = np.load(f'{data_dir}/duration.npy')\n",
    "    gops = np.load(f'{data_dir}/gop.npy')\n",
    "    wavlm_features = np.load(f'{data_dir}/wavlm_features.npy')\n",
    "\n",
    "    return phone_ids, phone_scores, durations, gops, wavlm_features\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torch\n",
    "\n",
    "class PrepDataset(Dataset):\n",
    "    def __init__(self, phone_ids, phone_scores, durations, gops, wavlm_features):\n",
    "        self.phone_ids = phone_ids\n",
    "        self.phone_scores = phone_scores\n",
    "        self.gops = gops\n",
    "        self.durations = durations\n",
    "        self.wavlm_features = wavlm_features\n",
    "        \n",
    "    def __len__(self):\n",
    "        return self.phone_ids.shape[0]\n",
    "    \n",
    "    def parse_data(self, phone_ids, phone_scores, gops, durations, wavlm_features):\n",
    "        phone_ids = torch.tensor(phone_ids)\n",
    "        durations = torch.tensor(durations)\n",
    "        gops = torch.tensor(gops)\n",
    "        phone_scores = torch.tensor(phone_scores).float().clone()\n",
    "        wavlm_features = torch.tensor(wavlm_features)\n",
    "\n",
    "        phone_scores[phone_scores != -1] /= 50\n",
    "\n",
    "        features = torch.concat([gops, durations.unsqueeze(-1), wavlm_features], dim=-1)        \n",
    "        return {\n",
    "            \"features\": features,\n",
    "            \"phone_ids\": phone_ids,\n",
    "            \"phone_scores\":phone_scores\n",
    "        }\n",
    "\n",
    "        \n",
    "    def __getitem__(self, index):\n",
    "        phone_ids = self.phone_ids[index]\n",
    "        phone_scores = self.phone_scores[index]\n",
    "        gops = self.gops[index]\n",
    "        durations = self.durations[index]\n",
    "        wavlm_features = self.wavlm_features[index]\n",
    "\n",
    "        return self.parse_data(\n",
    "            phone_ids=phone_ids,\n",
    "            phone_scores=phone_scores,\n",
    "            gops=gops,\n",
    "            durations=durations,\n",
    "            wavlm_features=wavlm_features\n",
    "        )\n",
    "\n",
    "data_dir = \"/data/codes/prep_ps_pykaldi/exp/sm/test\"\n",
    "\n",
    "phone_ids, phone_scores, durations, gops, wavlm_features = load_data(data_dir)\n",
    "dataset_v1 = PrepDataset(phone_ids, phone_scores, durations, gops, wavlm_features)\n",
    "dataloader = DataLoader(dataset_v1, batch_size=8)\n",
    "\n",
    "for batch in dataloader:\n",
    "    features = batch[\"features\"]\n",
    "    phone_ids = batch[\"phone_ids\"]\n",
    "    phone_scores = batch[\"phone_scores\"]\n",
    "    \n",
    "    print(features.shape)\n",
    "    print(phone_ids.shape)\n",
    "    print(phone_scores.shape)\n",
    "    break\n",
    "\n",
    "dataset_v1 = None\n",
    "dataloader = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import warnings\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "\n",
    "def get_sinusoid_encoding(n_position, d_hid):\n",
    "    def get_position_angle_vec(position):\n",
    "        return [position / np.power(10000, 2 * (hid_j // 2) / d_hid) for hid_j in range(d_hid)]\n",
    "\n",
    "    sinusoid_table = np.array([get_position_angle_vec(pos_i) for pos_i in range(n_position)])\n",
    "    sinusoid_table[:, 0::2] = np.sin(sinusoid_table[:, 0::2])  # dim 2i\n",
    "    sinusoid_table[:, 1::2] = np.cos(sinusoid_table[:, 1::2])  # dim 2i+1\n",
    "\n",
    "    return torch.FloatTensor(sinusoid_table).unsqueeze(0)\n",
    "\n",
    "\n",
    "def _no_grad_trunc_normal_(tensor, mean, std, a, b):\n",
    "    def norm_cdf(x):\n",
    "        return (1. + math.erf(x / math.sqrt(2.))) / 2.\n",
    "\n",
    "    if (mean < a - 2 * std) or (mean > b + 2 * std):\n",
    "        warnings.warn(\"mean is more than 2 std from [a, b] in nn.init.trunc_normal_. \"\n",
    "                      \"The distribution of values may be incorrect.\",\n",
    "                      stacklevel=2)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        l = norm_cdf((a - mean) / std)\n",
    "        u = norm_cdf((b - mean) / std)\n",
    "\n",
    "        tensor.uniform_(2 * l - 1, 2 * u - 1)\n",
    "        tensor.erfinv_()\n",
    "        tensor.mul_(std * math.sqrt(2.))\n",
    "        tensor.add_(mean)\n",
    "        tensor.clamp_(min=a, max=b)\n",
    "        \n",
    "        return tensor\n",
    "\n",
    "def trunc_normal_(tensor, mean=0., std=1., a=-2., b=2.):\n",
    "    return _no_grad_trunc_normal_(tensor, mean, std, a, b)\n",
    "\n",
    "class Attention(nn.Module):\n",
    "    def __init__(self, dim, num_heads=8, qkv_bias=False, qk_scale=None, attn_drop=0., proj_drop=0.):\n",
    "        super().__init__()\n",
    "        self.num_heads = num_heads\n",
    "        head_dim = dim // num_heads\n",
    "        self.scale = qk_scale or head_dim ** -0.5\n",
    "\n",
    "        self.qkv = nn.Linear(dim, dim * 3, bias=qkv_bias)\n",
    "        self.attn_drop = nn.Dropout(attn_drop)\n",
    "        self.proj = nn.Linear(dim, dim)\n",
    "        self.proj_drop = nn.Dropout(proj_drop)\n",
    "\n",
    "    def forward(self, x):\n",
    "        B, N, C = x.shape\n",
    "        qkv = self.qkv(x).reshape(B, N, 3, self.num_heads, C // self.num_heads).permute(2, 0, 3, 1, 4)\n",
    "        q, k, v = qkv[0], qkv[1], qkv[2]   # make torchscript happy (cannot use tensor as tuple)\n",
    "\n",
    "        attn = (q @ k.transpose(-2, -1)) * self.scale\n",
    "        attn = attn.softmax(dim=-1)\n",
    "        attn = self.attn_drop(attn)\n",
    "\n",
    "        x = (attn @ v).transpose(1, 2).reshape(B, N, C)\n",
    "        x = self.proj(x)\n",
    "        x = self.proj_drop(x)\n",
    "        return x\n",
    "\n",
    "class Mlp(nn.Module):\n",
    "    def __init__(self, in_features, hidden_features=None, out_features=None, act_layer=nn.GELU, drop=0.):\n",
    "        super().__init__()\n",
    "        out_features = out_features or in_features\n",
    "        hidden_features = hidden_features or in_features\n",
    "        self.fc1 = nn.Linear(in_features, hidden_features)\n",
    "        self.act = act_layer()\n",
    "        self.fc2 = nn.Linear(hidden_features, out_features)\n",
    "        self.drop = nn.Dropout(drop)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.fc1(x)\n",
    "        x = self.act(x)\n",
    "        x = self.drop(x)\n",
    "        x = self.fc2(x)\n",
    "        x = self.drop(x)\n",
    "        return x\n",
    "\n",
    "class Block(nn.Module):\n",
    "    def __init__(self, dim, num_heads, mlp_ratio=4., qkv_bias=False, qk_scale=None, drop=0., attn_drop=0.,\n",
    "                 drop_path=0., act_layer=nn.GELU, norm_layer=nn.LayerNorm):\n",
    "        super().__init__()\n",
    "        self.norm1 = norm_layer(dim)\n",
    "        self.attn = Attention(\n",
    "            dim, num_heads=num_heads, qkv_bias=qkv_bias, qk_scale=qk_scale, attn_drop=attn_drop, proj_drop=drop)\n",
    "\n",
    "        self.drop_path = nn.Identity()\n",
    "        self.norm2 = norm_layer(dim)\n",
    "        mlp_hidden_dim = int(dim * mlp_ratio)\n",
    "        self.mlp = Mlp(in_features=dim, hidden_features=mlp_hidden_dim, act_layer=act_layer, drop=drop)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x + self.drop_path(self.attn(self.norm1(x)))\n",
    "        x = x + self.drop_path(self.mlp(self.norm2(x)))\n",
    "        return x\n",
    "\n",
    "class GOPT(nn.Module):\n",
    "    def __init__(self, embed_dim, num_heads, depth, input_dim=84, max_length=50, num_phone=40):\n",
    "        super().__init__()\n",
    "        self.input_dim = input_dim\n",
    "        self.embed_dim = embed_dim\n",
    "        self.blocks = nn.ModuleList(\n",
    "            [\n",
    "                Block(dim=embed_dim, num_heads=num_heads) \n",
    "                for i in range(depth)\n",
    "                ]\n",
    "            )\n",
    "\n",
    "        self.pos_embed = nn.Parameter(torch.zeros(1, max_length+1, self.embed_dim))\n",
    "        trunc_normal_(self.pos_embed, std=.02)\n",
    "\n",
    "        self.in_proj = nn.Linear(self.input_dim, embed_dim)\n",
    "        self.linear = nn.Linear(embed_dim * 2, embed_dim)\n",
    "        self.mlp_head_phn = nn.Sequential(\n",
    "            nn.LayerNorm(embed_dim), nn.Linear(embed_dim, 1))\n",
    "\n",
    "        self.mlp_head_word= nn.Sequential(\n",
    "            nn.LayerNorm(embed_dim), nn.Linear(embed_dim, 1))\n",
    "\n",
    "        self.num_phone = num_phone\n",
    "        self.phn_proj = nn.Linear(num_phone, embed_dim)\n",
    "\n",
    "        self.cls_token = nn.Parameter(torch.zeros(1, 1, embed_dim))\n",
    "        self.mlp_head_utt = nn.Sequential(nn.LayerNorm(embed_dim), nn.Linear(embed_dim, 1))\n",
    "\n",
    "        trunc_normal_(self.cls_token, std=.02)\n",
    "\n",
    "    def forward(self, x, phn):\n",
    "        B = x.shape[0]\n",
    "        phn_one_hot = torch.nn.functional.one_hot(phn.long()+1, num_classes=self.num_phone).float()\n",
    "        phn_embed = self.phn_proj(phn_one_hot)\n",
    "\n",
    "        if self.embed_dim != self.input_dim:\n",
    "            x = self.in_proj(x)\n",
    "\n",
    "        x = torch.cat([x, phn_embed], dim=-1)\n",
    "        x = self.linear(x)\n",
    "        \n",
    "        cls_token = self.cls_token.expand(B, -1, -1)\n",
    "        x = torch.cat((cls_token, x), dim=1)\n",
    "        x = x + self.pos_embed[:,:x.shape[1],:]\n",
    "\n",
    "        for blk in self.blocks:\n",
    "            x = blk(x)\n",
    "        u = self.mlp_head_utt(x[:, 0])\n",
    "        p = self.mlp_head_phn(x[:, 1:])\n",
    "        w = self.mlp_head_word(x[:, 1:])\n",
    "        return u, p, w"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.optim import Adam\n",
    "\n",
    "data_dir = \"/data/codes/prep_ps_pykaldi/exp/sm/train\"\n",
    "phone_ids, phone_scores, durations, gops, wavlm_features = load_data(data_dir)\n",
    "trainset = PrepDataset(\n",
    "    phone_ids, \n",
    "    phone_scores, \n",
    "    durations, \n",
    "    gops, \n",
    "    wavlm_features\n",
    ")\n",
    "\n",
    "trainloader = DataLoader(trainset, batch_size=8, shuffle=True, drop_last=False)\n",
    "\n",
    "data_dir = \"/data/codes/prep_ps_pykaldi/exp/sm/test\"\n",
    "phone_ids, phone_scores, durations, gops, wavlm_features = load_data(data_dir)\n",
    "testset = PrepDataset(\n",
    "    phone_ids, \n",
    "    phone_scores, \n",
    "    durations, \n",
    "    gops, \n",
    "    wavlm_features\n",
    ")\n",
    "\n",
    "testloader = DataLoader(testset, batch_size=8, shuffle=True, drop_last=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.optim.lr_scheduler import MultiStepLR\n",
    "from torch import nn\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "gopt_model = GOPT(\n",
    "    embed_dim=32, num_heads=1, \n",
    "    depth=3, input_dim=851, \n",
    "    max_length=128, num_phone=62).to(device)\n",
    "\n",
    "trainables = [p for p in gopt_model.parameters() if p.requires_grad]\n",
    "\n",
    "lr = 3e-4\n",
    "optimizer = torch.optim.Adam(\n",
    "    trainables, lr, weight_decay=5e-7, betas=(0.95, 0.999))\n",
    "\n",
    "scheduler = MultiStepLR(\n",
    "    optimizer, list(range(10, 100, 5)), gamma=0.5, last_epoch=-1)\n",
    "\n",
    "loss_fn = nn.MSELoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def valid_phn(audio_output, target):\n",
    "    valid_token_pred = []\n",
    "    valid_token_target = []\n",
    "    # audio_output = audio_output.squeeze(2)\n",
    "    for i in range(audio_output.shape[0]):\n",
    "        for j in range(audio_output.shape[1]):\n",
    "            # only count valid tokens, not padded tokens (represented by negative values)\n",
    "            if target[i, j] >= 0:\n",
    "                valid_token_pred.append(audio_output[i, j])\n",
    "                valid_token_target.append(target[i, j])\n",
    "    valid_token_target = np.array(valid_token_target)\n",
    "    valid_token_pred = np.array(valid_token_pred)\n",
    "\n",
    "    valid_token_mse = np.mean((valid_token_target - valid_token_pred) ** 2)\n",
    "    valid_token_mae = np.mean(np.abs(valid_token_target - valid_token_pred))\n",
    "    corr = np.corrcoef(valid_token_pred, valid_token_target)[0, 1]\n",
    "    return valid_token_mse, valid_token_mae, corr\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "global_step = 0\n",
    "for epoch in range(50):\n",
    "    gopt_model.train()\n",
    "    train_tqdm = tqdm(trainloader, \"Training\")\n",
    "\n",
    "    for batch in train_tqdm:\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        features = batch[\"features\"].to(device)\n",
    "        phone_ids = batch[\"phone_ids\"].to(device)\n",
    "        phone_labels = batch[\"phone_scores\"].to(device)\n",
    "\n",
    "        # warm_up_step = 100\n",
    "        # if global_step <= warm_up_step and global_step % 5 == 0:\n",
    "        #     warm_lr = (global_step / warm_up_step) * lr\n",
    "        #     for param_group in optimizer.param_groups:\n",
    "        #         param_group['lr'] = warm_lr\n",
    "\n",
    "        utterance_preds, phone_preds, word_preds = gopt_model(x=features.float(), phn=phone_ids.long())\n",
    "        \n",
    "        mask = phone_labels >=0\n",
    "        phone_preds = phone_preds.squeeze(2)\n",
    "        phone_preds = phone_preds * mask\n",
    "        phone_labels = phone_labels * mask\n",
    "        \n",
    "        loss_phn = loss_fn(phone_preds, phone_labels)\n",
    "        loss_phn = loss_phn * (mask.shape[0] * mask.shape[1]) / torch.sum(mask)\n",
    "        \n",
    "        loss_phn.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # if global_step > warm_up_step:\n",
    "        #     scheduler.step()\n",
    "        \n",
    "        global_step += 1\n",
    "        train_tqdm.set_postfix(loss_phn=loss_phn.item())\n",
    "    \n",
    "    A_phn, A_phn_target = [], []\n",
    "    for batch in testloader:\n",
    "        features = batch[\"features\"].to(device)\n",
    "        phone_ids = batch[\"phone_ids\"].to(device)\n",
    "        phone_labels = batch[\"phone_scores\"].to(device)\n",
    "        \n",
    "        utterance_preds, phone_preds, word_preds = gopt_model(x=features.float(), phn=phone_ids.long())\n",
    "        \n",
    "        phone_preds = phone_preds.detach().cpu()\n",
    "        phone_labels = phone_labels.detach().cpu()\n",
    "        \n",
    "        A_phn.append(phone_preds[:, :, 0])\n",
    "        A_phn_target.append(phone_labels)\n",
    "        \n",
    "    A_phn, A_phn_target  = torch.vstack(A_phn), torch.vstack(A_phn_target)\n",
    "    # valid_token_mse, valid_token_mae, corr\n",
    "    phn_mse, phn_mae, phn_corr = valid_phn(A_phn, A_phn_target)\n",
    "    print(f\"### Validation result: MSE={round(phn_mse, 4)} MAE={round(phn_mae, 4)} PCC={round(phn_corr, 4)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training: 100%|██████████| 1875/1875 [00:06<00:00, 282.83it/s, loss_phn=0.383] \n",
    "# ### Validation result: MSE=0.2248000055551529 MAE=0.32100000977516174 PCC=0.697\n",
    "# Training: 100%|██████████| 1875/1875 [00:06<00:00, 269.10it/s, loss_phn=0.121] \n",
    "# ### Validation result: MSE=0.20890000462532043 MAE=0.3012000024318695 PCC=0.7107\n",
    "# Training: 100%|██████████| 1875/1875 [00:07<00:00, 266.09it/s, loss_phn=0.408] \n",
    "# ### Validation result: MSE=0.20309999585151672 MAE=0.3140999972820282 PCC=0.7242\n",
    "# Training: 100%|██████████| 1875/1875 [00:07<00:00, 242.88it/s, loss_phn=0.2]   \n",
    "# ### Validation result: MSE=0.19470000267028809 MAE=0.2847999930381775 PCC=0.7351\n",
    "# Training: 100%|██████████| 1875/1875 [00:08<00:00, 226.88it/s, loss_phn=0.0942]\n",
    "# ### Validation result: MSE=0.19599999487400055 MAE=0.3019999861717224 PCC=0.7397\n",
    "# Training: 100%|██████████| 1875/1875 [00:08<00:00, 211.98it/s, loss_phn=0.0843]\n",
    "# ### Validation result: MSE=0.20020000636577606 MAE=0.2888000011444092 PCC=0.7336\n",
    "# Training: 100%|██████████| 1875/1875 [00:08<00:00, 215.95it/s, loss_phn=0.17]  \n",
    "# ### Validation result: MSE=0.19990000128746033 MAE=0.3253999948501587 PCC=0.7476\n",
    "# Training: 100%|██████████| 1875/1875 [00:08<00:00, 217.42it/s, loss_phn=0.235] \n",
    "# ### Validation result: MSE=0.19089999794960022 MAE=0.2535000145435333 PCC=0.7488\n",
    "# Training: 100%|██████████| 1875/1875 [00:08<00:00, 215.28it/s, loss_phn=0.196] \n",
    "# ### Validation result: MSE=0.18160000443458557 MAE=0.25870001316070557 PCC=0.7551\n",
    "# Training: 100%|██████████| 1875/1875 [00:08<00:00, 229.91it/s, loss_phn=0.0789]\n",
    "# ### Validation result: MSE=0.1860000044107437 MAE=0.27230000495910645 PCC=0.7551\n",
    "# Training: 100%|██████████| 1875/1875 [00:08<00:00, 220.74it/s, loss_phn=0.245] \n",
    "# ### Validation result: MSE=0.18070000410079956 MAE=0.2531000077724457 PCC=0.7567\n",
    "# Training: 100%|██████████| 1875/1875 [00:08<00:00, 217.68it/s, loss_phn=0.2]   \n",
    "# ### Validation result: MSE=0.17980000376701355 MAE=0.2590999901294708 PCC=0.7587\n",
    "# Training: 100%|██████████| 1875/1875 [00:08<00:00, 223.91it/s, loss_phn=0.269] \n",
    "# ### Validation result: MSE=0.18520000576972961 MAE=0.2809000015258789 PCC=0.7549\n",
    "# Training: 100%|██████████| 1875/1875 [00:08<00:00, 218.08it/s, loss_phn=0.136] \n",
    "# ### Validation result: MSE=0.1770000010728836 MAE=0.2590999901294708 PCC=0.7639\n",
    "# Training: 100%|██████████| 1875/1875 [00:08<00:00, 231.73it/s, loss_phn=0.222] \n",
    "# ### Validation result: MSE=0.17919999361038208 MAE=0.27320000529289246 PCC=0.7616\n",
    "# Training: 100%|██████████| 1875/1875 [00:08<00:00, 218.86it/s, loss_phn=0.14]  \n",
    "# ### Validation result: MSE=0.1808999925851822 MAE=0.2766999900341034 PCC=0.7592\n",
    "# Training: 100%|██████████| 1875/1875 [00:07<00:00, 243.76it/s, loss_phn=0.109] \n",
    "# ### Validation result: MSE=0.1776999980211258 MAE=0.25119999051094055 PCC=0.7633\n",
    "# Training: 100%|██████████| 1875/1875 [00:08<00:00, 224.56it/s, loss_phn=0.216] \n",
    "# ### Validation result: MSE=0.1761000007390976 MAE=0.2637999951839447 PCC=0.7658\n",
    "# Training: 100%|██████████| 1875/1875 [00:08<00:00, 225.93it/s, loss_phn=0.105] \n",
    "# ### Validation result: MSE=0.17810000479221344 MAE=0.2831999957561493 PCC=0.7658\n",
    "# Training: 100%|██████████| 1875/1875 [00:08<00:00, 228.92it/s, loss_phn=0.147] \n",
    "# ### Validation result: MSE=0.17800000309944153 MAE=0.23960000276565552 PCC=0.7648\n",
    "# Training: 100%|██████████| 1875/1875 [00:08<00:00, 226.74it/s, loss_phn=0.0989]\n",
    "# ### Validation result: MSE=0.1761000007390976 MAE=0.2502000033855438 PCC=0.7652\n",
    "# Training: 100%|██████████| 1875/1875 [00:08<00:00, 216.72it/s, loss_phn=0.136] \n",
    "# ### Validation result: MSE=0.17949999868869781 MAE=0.2687000036239624 PCC=0.7608\n",
    "# Training: 100%|██████████| 1875/1875 [00:08<00:00, 213.79it/s, loss_phn=0.0404]\n",
    "# ### Validation result: MSE=0.17720000445842743 MAE=0.25189998745918274 PCC=0.7622\n",
    "# Training: 100%|██████████| 1875/1875 [00:08<00:00, 224.79it/s, loss_phn=0.0969]\n",
    "# ### Validation result: MSE=0.1834000051021576 MAE=0.26460000872612 PCC=0.7539\n",
    "# Training: 100%|██████████| 1875/1875 [00:08<00:00, 220.28it/s, loss_phn=0.174] \n",
    "# ### Validation result: MSE=0.17720000445842743 MAE=0.2492000013589859 PCC=0.7639\n",
    "# Training: 100%|██████████| 1875/1875 [00:08<00:00, 219.94it/s, loss_phn=0.253] \n",
    "# ### Validation result: MSE=0.17839999496936798 MAE=0.251800000667572 PCC=0.7603\n",
    "# Training: 100%|██████████| 1875/1875 [00:07<00:00, 235.49it/s, loss_phn=0.118] \n",
    "# ### Validation result: MSE=0.17749999463558197 MAE=0.26579999923706055 PCC=0.764\n",
    "# Training: 100%|██████████| 1875/1875 [00:07<00:00, 236.08it/s, loss_phn=0.175] \n",
    "# ### Validation result: MSE=0.1818999946117401 MAE=0.24539999663829803 PCC=0.7586\n",
    "# Training: 100%|██████████| 1875/1875 [00:08<00:00, 230.76it/s, loss_phn=0.188] \n",
    "# ### Validation result: MSE=0.18610000610351562 MAE=0.27649998664855957 PCC=0.7561\n",
    "# Training: 100%|██████████| 1875/1875 [00:08<00:00, 226.30it/s, loss_phn=0.0649]\n",
    "# ### Validation result: MSE=0.1850000023841858 MAE=0.25200000405311584 PCC=0.7616\n",
    "# Training: 100%|██████████| 1875/1875 [00:08<00:00, 222.24it/s, loss_phn=0.277] \n",
    "# ### Validation result: MSE=0.18240000307559967 MAE=0.2583000063896179 PCC=0.7576\n",
    "# Training: 100%|██████████| 1875/1875 [00:08<00:00, 233.27it/s, loss_phn=0.118] \n",
    "# ### Validation result: MSE=0.18219999969005585 MAE=0.25850000977516174 PCC=0.7564\n",
    "# Training: 100%|██████████| 1875/1875 [00:08<00:00, 222.01it/s, loss_phn=0.176] \n",
    "# ### Validation result: MSE=0.18449999392032623 MAE=0.2515999972820282 PCC=0.7514\n",
    "# Training: 100%|██████████| 1875/1875 [00:08<00:00, 224.62it/s, loss_phn=0.158] \n",
    "# ### Validation result: MSE=0.19040000438690186 MAE=0.24060000479221344 PCC=0.7489\n",
    "# Training: 100%|██████████| 1875/1875 [00:08<00:00, 224.26it/s, loss_phn=0.115] \n",
    "# ### Validation result: MSE=0.19280000030994415 MAE=0.23849999904632568 PCC=0.7519\n",
    "# Training: 100%|██████████| 1875/1875 [00:08<00:00, 227.97it/s, loss_phn=0.103] \n",
    "# ### Validation result: MSE=0.18389999866485596 MAE=0.23899999260902405 PCC=0.757\n",
    "# Training: 100%|██████████| 1875/1875 [00:08<00:00, 228.36it/s, loss_phn=0.0634]\n",
    "# ### Validation result: MSE=0.1860000044107437 MAE=0.24860000610351562 PCC=0.7525\n",
    "# Training: 100%|██████████| 1875/1875 [00:08<00:00, 229.89it/s, loss_phn=0.104] \n",
    "# ### Validation result: MSE=0.18809999525547028 MAE=0.24690000712871552 PCC=0.7492\n",
    "# Training: 100%|██████████| 1875/1875 [00:08<00:00, 223.95it/s, loss_phn=0.102] \n",
    "# ### Validation result: MSE=0.18729999661445618 MAE=0.26499998569488525 PCC=0.7522\n",
    "# Training: 100%|██████████| 1875/1875 [00:08<00:00, 232.23it/s, loss_phn=0.165] \n",
    "# ### Validation result: MSE=0.188400000333786 MAE=0.24269999563694 PCC=0.7507\n",
    "# Training: 100%|██████████| 1875/1875 [00:08<00:00, 228.30it/s, loss_phn=0.0935]\n",
    "# ### Validation result: MSE=0.18790000677108765 MAE=0.24289999902248383 PCC=0.7523\n",
    "# Training: 100%|██████████| 1875/1875 [00:08<00:00, 227.63it/s, loss_phn=0.0525] \n",
    "# ### Validation result: MSE=0.19089999794960022 MAE=0.2556999921798706 PCC=0.746\n",
    "# Training: 100%|██████████| 1875/1875 [00:08<00:00, 229.75it/s, loss_phn=0.0636] \n",
    "# ### Validation result: MSE=0.19419999420642853 MAE=0.2393999993801117 PCC=0.7454\n",
    "# Training: 100%|██████████| 1875/1875 [00:08<00:00, 232.12it/s, loss_phn=0.0951]\n",
    "# ### Validation result: MSE=0.18770000338554382 MAE=0.24400000274181366 PCC=0.7504\n",
    "# Training: 100%|██████████| 1875/1875 [00:08<00:00, 232.98it/s, loss_phn=0.111] \n",
    "# ### Validation result: MSE=0.19140000641345978 MAE=0.24040000140666962 PCC=0.7481\n",
    "# Training: 100%|██████████| 1875/1875 [00:08<00:00, 226.29it/s, loss_phn=0.0311]\n",
    "# ### Validation result: MSE=0.1923999935388565 MAE=0.2410999983549118 PCC=0.7451\n",
    "# Training: 100%|██████████| 1875/1875 [00:08<00:00, 226.37it/s, loss_phn=0.124] \n",
    "# ### Validation result: MSE=0.1940000057220459 MAE=0.2451000064611435 PCC=0.7458\n",
    "# Training: 100%|██████████| 1875/1875 [00:08<00:00, 218.81it/s, loss_phn=0.078] \n",
    "# ### Validation result: MSE=0.19059999287128448 MAE=0.25780001282691956 PCC=0.749\n",
    "# Training: 100%|██████████| 1875/1875 [00:07<00:00, 241.92it/s, loss_phn=0.0821]\n",
    "# ### Validation result: MSE=0.19480000436306 MAE=0.25189998745918274 PCC=0.7401\n",
    "# Training: 100%|██████████| 1875/1875 [00:08<00:00, 218.41it/s, loss_phn=0.0773] \n",
    "# ### Validation result: MSE=0.2020999938249588 MAE=0.25769999623298645 PCC=0.7357"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ps",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.17"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
