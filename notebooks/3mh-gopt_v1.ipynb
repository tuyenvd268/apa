{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/data/codes/prep_ps_pykaldi\n"
     ]
    }
   ],
   "source": [
    "%cd /data/codes/prep_ps_pykaldi/\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pickle\n",
    "import json\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>uid</th>\n",
       "      <th>id</th>\n",
       "      <th>qid</th>\n",
       "      <th>text</th>\n",
       "      <th>arpas</th>\n",
       "      <th>phone_scores</th>\n",
       "      <th>trans</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>84964.0</td>\n",
       "      <td>4140010</td>\n",
       "      <td>10270</td>\n",
       "      <td>WARM</td>\n",
       "      <td>[W, AO1, R, M]</td>\n",
       "      <td>[98, 96, 83, 99]</td>\n",
       "      <td>[W, AO, R, M]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>84964.0</td>\n",
       "      <td>4140013</td>\n",
       "      <td>10272</td>\n",
       "      <td>FLOOD</td>\n",
       "      <td>[F, L, AH1, D]</td>\n",
       "      <td>[100, 100, 0, 0]</td>\n",
       "      <td>[F, L, AE, T]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>84964.0</td>\n",
       "      <td>4140015</td>\n",
       "      <td>10273</td>\n",
       "      <td>FOGGY</td>\n",
       "      <td>[F, AA1, G, IY0]</td>\n",
       "      <td>[100, 95, 81, 100]</td>\n",
       "      <td>[F, AA, G, IY]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>84964.0</td>\n",
       "      <td>4140018</td>\n",
       "      <td>10274</td>\n",
       "      <td>CHILLY</td>\n",
       "      <td>[CH, IH1, L, IY0]</td>\n",
       "      <td>[97, 94, 98, 99]</td>\n",
       "      <td>[CH, IH, L, IY]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>84964.0</td>\n",
       "      <td>4140023</td>\n",
       "      <td>10276</td>\n",
       "      <td>THUNDERSTORM</td>\n",
       "      <td>[TH, AH1, N, D, ER0, S, T, AO2, R, M]</td>\n",
       "      <td>[0, 95, 100, 100, 87, 90, 93, 97, 38, 5]</td>\n",
       "      <td>[F, AH, N, D, ER, S, T, AO, L, &lt;eps&gt;]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       uid       id    qid          text  \\\n",
       "0  84964.0  4140010  10270          WARM   \n",
       "1  84964.0  4140013  10272         FLOOD   \n",
       "2  84964.0  4140015  10273         FOGGY   \n",
       "3  84964.0  4140018  10274        CHILLY   \n",
       "4  84964.0  4140023  10276  THUNDERSTORM   \n",
       "\n",
       "                                   arpas  \\\n",
       "0                         [W, AO1, R, M]   \n",
       "1                         [F, L, AH1, D]   \n",
       "2                       [F, AA1, G, IY0]   \n",
       "3                      [CH, IH1, L, IY0]   \n",
       "4  [TH, AH1, N, D, ER0, S, T, AO2, R, M]   \n",
       "\n",
       "                               phone_scores  \\\n",
       "0                          [98, 96, 83, 99]   \n",
       "1                          [100, 100, 0, 0]   \n",
       "2                        [100, 95, 81, 100]   \n",
       "3                          [97, 94, 98, 99]   \n",
       "4  [0, 95, 100, 100, 87, 90, 93, 97, 38, 5]   \n",
       "\n",
       "                                   trans  \n",
       "0                          [W, AO, R, M]  \n",
       "1                          [F, L, AE, T]  \n",
       "2                         [F, AA, G, IY]  \n",
       "3                        [CH, IH, L, IY]  \n",
       "4  [F, AH, N, D, ER, S, T, AO, L, <eps>]  "
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def load_jsonl(path):\n",
    "    with open(path, \"r\", encoding=\"utf-8\") as f:\n",
    "        lines = f.readlines()\n",
    "        lines = [json.loads(line.strip()) for line in lines]\n",
    "    \n",
    "    return lines\n",
    "\n",
    "path = \"prep_data/info_in_domain_short_sentence_testset.jsonl\"\n",
    "metadata = load_jsonl(path)\n",
    "metadata = pd.DataFrame(metadata)\n",
    "metadata.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>uid</th>\n",
       "      <th>id</th>\n",
       "      <th>qid</th>\n",
       "      <th>text</th>\n",
       "      <th>arpas</th>\n",
       "      <th>phone_scores</th>\n",
       "      <th>trans</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>84964.0</td>\n",
       "      <td>4140010</td>\n",
       "      <td>10270</td>\n",
       "      <td>WARM</td>\n",
       "      <td>[W, AO1, R, M]</td>\n",
       "      <td>[98, 96, 83, 99]</td>\n",
       "      <td>[W, AO, R, M]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>84964.0</td>\n",
       "      <td>4140013</td>\n",
       "      <td>10272</td>\n",
       "      <td>FLOOD</td>\n",
       "      <td>[F, L, AH1, D]</td>\n",
       "      <td>[100, 100, 0, 0]</td>\n",
       "      <td>[F, L, AE, T]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       uid       id    qid   text           arpas      phone_scores  \\\n",
       "0  84964.0  4140010  10270   WARM  [W, AO1, R, M]  [98, 96, 83, 99]   \n",
       "1  84964.0  4140013  10272  FLOOD  [F, L, AH1, D]  [100, 100, 0, 0]   \n",
       "\n",
       "           trans  \n",
       "0  [W, AO, R, M]  \n",
       "1  [F, L, AE, T]  "
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with open('/data/codes/prep_ps_pykaldi/exp/sm/test/merged_gop.pkl', 'rb') as f:\n",
    "    data = pickle.load(f)\n",
    "metadata = metadata[metadata.id.isin(data)]\n",
    "metadata.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>uid</th>\n",
       "      <th>id</th>\n",
       "      <th>qid</th>\n",
       "      <th>text</th>\n",
       "      <th>arpas</th>\n",
       "      <th>phone_scores</th>\n",
       "      <th>trans</th>\n",
       "      <th>features</th>\n",
       "      <th>kaldi_phoneme</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>84964.0</td>\n",
       "      <td>4140010</td>\n",
       "      <td>10270</td>\n",
       "      <td>WARM</td>\n",
       "      <td>[W, AO1, R, M]</td>\n",
       "      <td>[98, 96, 83, 99]</td>\n",
       "      <td>[W, AO, R, M]</td>\n",
       "      <td>[[-8.474355164650865, -6.19096396237338, -3.46...</td>\n",
       "      <td>[W, AO, R, M]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>84964.0</td>\n",
       "      <td>4140013</td>\n",
       "      <td>10272</td>\n",
       "      <td>FLOOD</td>\n",
       "      <td>[F, L, AH1, D]</td>\n",
       "      <td>[100, 100, 0, 0]</td>\n",
       "      <td>[F, L, AE, T]</td>\n",
       "      <td>[[-7.494081062137129, -5.934803005425601, -3.7...</td>\n",
       "      <td>[F, L, AH, D]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       uid       id    qid   text           arpas      phone_scores  \\\n",
       "0  84964.0  4140010  10270   WARM  [W, AO1, R, M]  [98, 96, 83, 99]   \n",
       "1  84964.0  4140013  10272  FLOOD  [F, L, AH1, D]  [100, 100, 0, 0]   \n",
       "\n",
       "           trans                                           features  \\\n",
       "0  [W, AO, R, M]  [[-8.474355164650865, -6.19096396237338, -3.46...   \n",
       "1  [F, L, AE, T]  [[-7.494081062137129, -5.934803005425601, -3.7...   \n",
       "\n",
       "   kaldi_phoneme  \n",
       "0  [W, AO, R, M]  \n",
       "1  [F, L, AH, D]  "
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def extract_gop_feature(id):\n",
    "    sample = data[str(id)]\n",
    "    features = [\n",
    "        np.array(feature) for feature, phoneme in zip(sample[\"gopt\"], sample[\"phones\"][0])\n",
    "        if phoneme != \"SIL\"\n",
    "    ]\n",
    "    return np.stack(features)\n",
    "\n",
    "def extract_phonemes(id):\n",
    "    sample = data[str(id)]\n",
    "    phonemes = [\n",
    "        re.sub(\"\\d\", \"\",phoneme.split(\"_\")[0]) for phoneme in sample[\"phones\"][0]\n",
    "        if phoneme != \"SIL\"\n",
    "    ]\n",
    "    return phonemes\n",
    "\n",
    "metadata[\"features\"] = metadata.id.apply(lambda x: extract_gop_feature(x))\n",
    "metadata[\"kaldi_phoneme\"] = metadata.id.apply(lambda x: extract_phonemes(x))\n",
    "metadata.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>alignment</th>\n",
       "      <th>durations</th>\n",
       "      <th>phonemes</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3666010</td>\n",
       "      <td>[[\"SIL\", 0, 265], [\"K_B\", 265, 15], [\"AO1_I\", ...</td>\n",
       "      <td>[0.3, 0.14, 0.12, 0.34, 0.28, 0.42, 0.4]</td>\n",
       "      <td>[K, AO1, R, P, ER0, AH0, T]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3666014</td>\n",
       "      <td>[[\"SIL\", 0, 17], [\"K_B\", 17, 14], [\"AE1_I\", 31...</td>\n",
       "      <td>[0.28, 0.4, 0.12, 0.24]</td>\n",
       "      <td>[K, AE1, T, S]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3666016</td>\n",
       "      <td>[[\"SIL\", 0, 25], [\"D_B\", 25, 11], [\"AA1_I\", 36...</td>\n",
       "      <td>[0.22, 0.5, 0.2, 0.52]</td>\n",
       "      <td>[D, AA1, G, Z]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3666017</td>\n",
       "      <td>[[\"SIL\", 0, 257], [\"IH0_B\", 257, 10], [\"N_I\", ...</td>\n",
       "      <td>[0.2, 0.12, 0.34, 0.5, 0.28, 0.22, 0.2, 0.34]</td>\n",
       "      <td>[IH0, N, SH, UH1, R, AH0, N, S]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3666020</td>\n",
       "      <td>[[\"SIL\", 0, 9], [\"S_B\", 9, 13], [\"T_I\", 22, 11...</td>\n",
       "      <td>[0.26, 0.22, 0.54, 0.14, 0.04]</td>\n",
       "      <td>[S, T, AA1, P, S]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        id                                          alignment  \\\n",
       "0  3666010  [[\"SIL\", 0, 265], [\"K_B\", 265, 15], [\"AO1_I\", ...   \n",
       "1  3666014  [[\"SIL\", 0, 17], [\"K_B\", 17, 14], [\"AE1_I\", 31...   \n",
       "2  3666016  [[\"SIL\", 0, 25], [\"D_B\", 25, 11], [\"AA1_I\", 36...   \n",
       "3  3666017  [[\"SIL\", 0, 257], [\"IH0_B\", 257, 10], [\"N_I\", ...   \n",
       "4  3666020  [[\"SIL\", 0, 9], [\"S_B\", 9, 13], [\"T_I\", 22, 11...   \n",
       "\n",
       "                                       durations  \\\n",
       "0       [0.3, 0.14, 0.12, 0.34, 0.28, 0.42, 0.4]   \n",
       "1                        [0.28, 0.4, 0.12, 0.24]   \n",
       "2                         [0.22, 0.5, 0.2, 0.52]   \n",
       "3  [0.2, 0.12, 0.34, 0.5, 0.28, 0.22, 0.2, 0.34]   \n",
       "4                 [0.26, 0.22, 0.54, 0.14, 0.04]   \n",
       "\n",
       "                          phonemes  \n",
       "0      [K, AO1, R, P, ER0, AH0, T]  \n",
       "1                   [K, AE1, T, S]  \n",
       "2                   [D, AA1, G, Z]  \n",
       "3  [IH0, N, SH, UH1, R, AH0, N, S]  \n",
       "4                [S, T, AA1, P, S]  "
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "align_path = \"/data/codes/prep_ps_pykaldi/exp/sm/test/merged_align.out\"\n",
    "align_df = pd.read_csv(align_path, names=[\"id\", \"alignment\"], sep=\"\\t\")\n",
    "\n",
    "def extract_duration(alignment):\n",
    "    alignment = json.loads(alignment)\n",
    "    durations = []\n",
    "    \n",
    "    for phoneme, start, duration in alignment:\n",
    "        if phoneme == \"SIL\":\n",
    "            continue\n",
    "        durations.append(round(duration * 0.02, 4))\n",
    "\n",
    "    return durations\n",
    "\n",
    "def extract_phonemes(alignment):\n",
    "    alignment = json.loads(alignment)\n",
    "    phonemes = []\n",
    "    \n",
    "    for phoneme, start, duration in alignment:\n",
    "        if phoneme == \"SIL\":\n",
    "            continue\n",
    "        phonemes.append(phoneme.split(\"_\")[0])\n",
    "\n",
    "    return phonemes\n",
    "\n",
    "align_df[\"durations\"] = align_df[\"alignment\"].apply(lambda x: extract_duration(x))\n",
    "align_df[\"phonemes\"] = align_df[\"alignment\"].apply(lambda x: extract_phonemes(x))\n",
    "align_df[\"id\"] = align_df[\"id\"].apply(str)\n",
    "align_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "metadata = pd.merge(metadata, align_df[[\"id\", \"durations\"]], how=\"left\", on=\"id\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "import pickle\n",
    "\n",
    "features = metadata[\"features\"].to_list()\n",
    "features = np.concatenate(features)\n",
    "\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(features)\n",
    "\n",
    "with open('resources/scaler.pkl','wb') as f:\n",
    "    pickle.dump(scaler, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# phone_dict = []\n",
    "# for word in metadata[\"arpas\"].to_list():\n",
    "#     phone_dict += word\n",
    "# phone_dict = list(set(phone_dict))\n",
    "# phone_dict.sort()\n",
    "\n",
    "# phone_dict.insert(0, \"PAD\")\n",
    "# vocab= {}\n",
    "# for key in phone_dict:\n",
    "#     key = re.sub(\"\\d\", \"\", key)\n",
    "#     if key not in vocab:\n",
    "#         vocab[key] = len(vocab)\n",
    "# phone_dict = {re.sub(\"\\d\", \"\", key):value for value, key in enumerate(phone_dict)}\n",
    "\n",
    "# with open(\"resources/phone_dict.json\", \"w\", encoding=\"utf-8\") as f:\n",
    "#     json_obj = json.dumps(vocab, indent=4, ensure_ascii=False)\n",
    "#     f.write(json_obj)\n",
    "\n",
    "with open(\"resources/phone_dict.json\", \"r\", encoding=\"utf-8\") as f:\n",
    "    phone_dict = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "metadata['phones'] = metadata[\"arpas\"].apply(lambda word: [phone_dict[re.sub(\"\\d\", \"\", x)] for x in word])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([8, 64, 83])\n",
      "torch.Size([8, 64])\n",
      "torch.Size([8, 64])\n"
     ]
    }
   ],
   "source": [
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torch\n",
    "\n",
    "class PrepDataset(Dataset):\n",
    "    def __init__(self, metadata,):\n",
    "        self.metadata = metadata\n",
    "        self.scaler = pickle.load(open('resources/scaler.pkl','rb'))\n",
    "    \n",
    "    def __len__(self):\n",
    "        return self.metadata.shape[0]\n",
    "    \n",
    "    def parse_data(self, features, phones, phone_scores, durations):\n",
    "        features = torch.tensor(features)\n",
    "        durations = torch.tensor(durations)\n",
    "        phones = torch.tensor(phones)\n",
    "        phone_scores = torch.tensor(phone_scores) / 50\n",
    "\n",
    "        features = torch.concat([features, durations.unsqueeze(-1)], dim=-1)        \n",
    "        return {\n",
    "            \"features\": features,\n",
    "            \"phones\": phones,\n",
    "            \"phone_scores\":phone_scores\n",
    "        }\n",
    "        \n",
    "    def __getitem__(self, index):\n",
    "        features = self.metadata[\"features\"][index]\n",
    "\n",
    "        features = self.scaler.transform(features)\n",
    "        phones = self.metadata[\"phones\"][index]\n",
    "        phone_scores = self.metadata[\"phone_scores\"][index]\n",
    "        durations =self.metadata[\"durations\"][index]\n",
    "\n",
    "        return self.parse_data(\n",
    "            features=features, \n",
    "            phones=phones, \n",
    "            phone_scores=phone_scores,\n",
    "            durations=durations\n",
    "        )\n",
    "        \n",
    "    def pad_1d(self, input_ids, pad_value=-1, max_length=64):\n",
    "        if max_length is None:\n",
    "            max_length = max([len(sample) for sample in input_ids])        \n",
    "            \n",
    "        attention_masks = []\n",
    "        for i in range(len(input_ids)):\n",
    "            if input_ids[i].size(0) < max_length:\n",
    "                input_ids[i] = torch.cat(\n",
    "                    (\n",
    "                        input_ids[i], \n",
    "                        torch.Tensor([pad_value, ]*(max_length-len(input_ids[i])))\n",
    "                        )\n",
    "                    )\n",
    "            elif input_ids[i].size(0) > max_length:\n",
    "                input_ids[i] = input_ids[i][0:max_length]\n",
    "                \n",
    "            attention_masks.append(input_ids[i] != pad_value)\n",
    "            \n",
    "        return {\n",
    "            \"input_ids\": torch.vstack(input_ids),\n",
    "            \"attention_mask\": torch.vstack(attention_masks)\n",
    "        }\n",
    "        \n",
    "    def pad_2d(self, inputs, pad_value=0, max_length=64):\n",
    "        # max_length = max([len(sample) for sample in inputs])        \n",
    "            \n",
    "        for i in range(len(inputs)):\n",
    "            if inputs[i].size(0) < max_length:\n",
    "                inputs[i] = torch.cat(\n",
    "                    (\n",
    "                        inputs[i], \n",
    "                        pad_value*torch.ones((max_length-len(inputs[i]), 83))\n",
    "                        )\n",
    "                    )\n",
    "            elif inputs[i].size(0) > max_length:\n",
    "                inputs[i] = inputs[i][0:max_length]\n",
    "                \n",
    "        return torch.stack(inputs, dim=0)\n",
    "        \n",
    "    \n",
    "    def collate_fn(self, batch):\n",
    "        features = [sample[\"features\"] for sample in batch]\n",
    "        phone_scores = [sample[\"phone_scores\"] for sample in batch]\n",
    "        phones = [sample[\"phones\"] for sample in batch]\n",
    "        \n",
    "        outputs = self.pad_1d(phones, pad_value=0)\n",
    "        phones = outputs[\"input_ids\"]\n",
    "        phones_mask = outputs[\"attention_mask\"]\n",
    "        \n",
    "        outputs = self.pad_1d(phone_scores, pad_value=-1)\n",
    "        phone_scores = outputs[\"input_ids\"]\n",
    "        \n",
    "        features = self.pad_2d(features, pad_value=0)\n",
    "                     \n",
    "        return {\n",
    "            \"features\": features,\n",
    "            \"phones\": phones,\n",
    "            \"phone_scores\": phone_scores\n",
    "        }\n",
    "\n",
    "dataset = PrepDataset(metadata)\n",
    "dataloader = DataLoader(dataset, batch_size=8, collate_fn=dataset.collate_fn)\n",
    "\n",
    "for batch in dataloader:\n",
    "    features = batch[\"features\"]\n",
    "    phones = batch[\"phones\"]\n",
    "    phone_scores = batch[\"phone_scores\"]\n",
    "    \n",
    "    print(features.shape)\n",
    "    print(phones.shape)\n",
    "    print(phone_scores.shape)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import warnings\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "\n",
    "def get_sinusoid_encoding(n_position, d_hid):\n",
    "    def get_position_angle_vec(position):\n",
    "        return [position / np.power(10000, 2 * (hid_j // 2) / d_hid) for hid_j in range(d_hid)]\n",
    "\n",
    "    sinusoid_table = np.array([get_position_angle_vec(pos_i) for pos_i in range(n_position)])\n",
    "    sinusoid_table[:, 0::2] = np.sin(sinusoid_table[:, 0::2])  # dim 2i\n",
    "    sinusoid_table[:, 1::2] = np.cos(sinusoid_table[:, 1::2])  # dim 2i+1\n",
    "\n",
    "    return torch.FloatTensor(sinusoid_table).unsqueeze(0)\n",
    "\n",
    "\n",
    "def _no_grad_trunc_normal_(tensor, mean, std, a, b):\n",
    "    def norm_cdf(x):\n",
    "        return (1. + math.erf(x / math.sqrt(2.))) / 2.\n",
    "\n",
    "    if (mean < a - 2 * std) or (mean > b + 2 * std):\n",
    "        warnings.warn(\"mean is more than 2 std from [a, b] in nn.init.trunc_normal_. \"\n",
    "                      \"The distribution of values may be incorrect.\",\n",
    "                      stacklevel=2)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        l = norm_cdf((a - mean) / std)\n",
    "        u = norm_cdf((b - mean) / std)\n",
    "\n",
    "        tensor.uniform_(2 * l - 1, 2 * u - 1)\n",
    "        tensor.erfinv_()\n",
    "        tensor.mul_(std * math.sqrt(2.))\n",
    "        tensor.add_(mean)\n",
    "        tensor.clamp_(min=a, max=b)\n",
    "        \n",
    "        return tensor\n",
    "\n",
    "def trunc_normal_(tensor, mean=0., std=1., a=-2., b=2.):\n",
    "    return _no_grad_trunc_normal_(tensor, mean, std, a, b)\n",
    "\n",
    "class Attention(nn.Module):\n",
    "    def __init__(self, dim, num_heads=8, qkv_bias=False, qk_scale=None, attn_drop=0., proj_drop=0.):\n",
    "        super().__init__()\n",
    "        self.num_heads = num_heads\n",
    "        head_dim = dim // num_heads\n",
    "        self.scale = qk_scale or head_dim ** -0.5\n",
    "\n",
    "        self.qkv = nn.Linear(dim, dim * 3, bias=qkv_bias)\n",
    "        self.attn_drop = nn.Dropout(attn_drop)\n",
    "        self.proj = nn.Linear(dim, dim)\n",
    "        self.proj_drop = nn.Dropout(proj_drop)\n",
    "\n",
    "    def forward(self, x):\n",
    "        B, N, C = x.shape\n",
    "        qkv = self.qkv(x).reshape(B, N, 3, self.num_heads, C // self.num_heads).permute(2, 0, 3, 1, 4)\n",
    "        q, k, v = qkv[0], qkv[1], qkv[2]   # make torchscript happy (cannot use tensor as tuple)\n",
    "\n",
    "        attn = (q @ k.transpose(-2, -1)) * self.scale\n",
    "        attn = attn.softmax(dim=-1)\n",
    "        attn = self.attn_drop(attn)\n",
    "\n",
    "        x = (attn @ v).transpose(1, 2).reshape(B, N, C)\n",
    "        x = self.proj(x)\n",
    "        x = self.proj_drop(x)\n",
    "        return x\n",
    "\n",
    "class Mlp(nn.Module):\n",
    "    def __init__(self, in_features, hidden_features=None, out_features=None, act_layer=nn.GELU, drop=0.):\n",
    "        super().__init__()\n",
    "        out_features = out_features or in_features\n",
    "        hidden_features = hidden_features or in_features\n",
    "        self.fc1 = nn.Linear(in_features, hidden_features)\n",
    "        self.act = act_layer()\n",
    "        self.fc2 = nn.Linear(hidden_features, out_features)\n",
    "        self.drop = nn.Dropout(drop)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.fc1(x)\n",
    "        x = self.act(x)\n",
    "        x = self.drop(x)\n",
    "        x = self.fc2(x)\n",
    "        x = self.drop(x)\n",
    "        return x\n",
    "\n",
    "class Block(nn.Module):\n",
    "    def __init__(self, dim, num_heads, mlp_ratio=4., qkv_bias=False, qk_scale=None, drop=0., attn_drop=0.,\n",
    "                 drop_path=0., act_layer=nn.GELU, norm_layer=nn.LayerNorm):\n",
    "        super().__init__()\n",
    "        self.norm1 = norm_layer(dim)\n",
    "        self.attn = Attention(\n",
    "            dim, num_heads=num_heads, qkv_bias=qkv_bias, qk_scale=qk_scale, attn_drop=attn_drop, proj_drop=drop)\n",
    "\n",
    "        self.drop_path = nn.Identity()\n",
    "        self.norm2 = norm_layer(dim)\n",
    "        mlp_hidden_dim = int(dim * mlp_ratio)\n",
    "        self.mlp = Mlp(in_features=dim, hidden_features=mlp_hidden_dim, act_layer=act_layer, drop=drop)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x + self.drop_path(self.attn(self.norm1(x)))\n",
    "        x = x + self.drop_path(self.mlp(self.norm2(x)))\n",
    "        return x\n",
    "\n",
    "class GOPT(nn.Module):\n",
    "    def __init__(self, embed_dim, num_heads, depth, input_dim=84, max_length=50, num_phone=40):\n",
    "        super().__init__()\n",
    "        self.input_dim = input_dim\n",
    "        self.embed_dim = embed_dim\n",
    "        self.blocks = nn.ModuleList(\n",
    "            [\n",
    "                Block(dim=embed_dim, num_heads=num_heads) \n",
    "                for i in range(depth)\n",
    "                ]\n",
    "            )\n",
    "\n",
    "        self.pos_embed = nn.Parameter(torch.zeros(1, max_length+1, self.embed_dim))\n",
    "        trunc_normal_(self.pos_embed, std=.02)\n",
    "\n",
    "        self.in_proj = nn.Linear(self.input_dim, embed_dim)\n",
    "        self.linear = nn.Linear(embed_dim * 2, embed_dim)\n",
    "        self.mlp_head_phn = nn.Sequential(\n",
    "            nn.LayerNorm(embed_dim), nn.Linear(embed_dim, 1))\n",
    "\n",
    "        self.mlp_head_word= nn.Sequential(\n",
    "            nn.LayerNorm(embed_dim), nn.Linear(embed_dim, 1))\n",
    "\n",
    "        self.num_phone = num_phone\n",
    "        self.phn_proj = nn.Linear(num_phone, embed_dim)\n",
    "\n",
    "        self.cls_token = nn.Parameter(torch.zeros(1, 1, embed_dim))\n",
    "        self.mlp_head_utt = nn.Sequential(nn.LayerNorm(embed_dim), nn.Linear(embed_dim, 1))\n",
    "\n",
    "        trunc_normal_(self.cls_token, std=.02)\n",
    "\n",
    "    def forward(self, x, phn):\n",
    "        B = x.shape[0]\n",
    "        phn_one_hot = torch.nn.functional.one_hot(phn.long()+1, num_classes=self.num_phone).float()\n",
    "        phn_embed = self.phn_proj(phn_one_hot)\n",
    "\n",
    "        if self.embed_dim != self.input_dim:\n",
    "            x = self.in_proj(x)\n",
    "\n",
    "        x = torch.cat([x, phn_embed], dim=-1)\n",
    "        x = self.linear(x)\n",
    "        \n",
    "        cls_token = self.cls_token.expand(B, -1, -1)\n",
    "        x = torch.cat((cls_token, x), dim=1)\n",
    "        x = x + self.pos_embed[:,:x.shape[1],:]\n",
    "\n",
    "        for blk in self.blocks:\n",
    "            x = blk(x)\n",
    "        u = self.mlp_head_utt(x[:, 0])\n",
    "        p = self.mlp_head_phn(x[:, 1:])\n",
    "        w = self.mlp_head_word(x[:, 1:])\n",
    "        return u, p, w"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.optim import Adam\n",
    "\n",
    "# trainset, testset = train_test_split(metadata, test_size=0.5, random_state=42)\n",
    "index = 15000\n",
    "trainset = metadata[:index]\n",
    "testset = metadata[index:]\n",
    "\n",
    "trainset.reset_index(inplace=True)\n",
    "testset.reset_index(inplace=True)\n",
    "\n",
    "trainset = PrepDataset(trainset)\n",
    "trainloader = DataLoader(\n",
    "    dataset=trainset,\n",
    "    batch_size=8,\n",
    "    collate_fn=trainset.collate_fn,\n",
    "    shuffle=True,\n",
    "    drop_last=False\n",
    ")\n",
    "\n",
    "testset = PrepDataset(testset)\n",
    "testloader = DataLoader(\n",
    "    dataset=testset,\n",
    "    batch_size=1,\n",
    "    collate_fn=testset.collate_fn,\n",
    "    shuffle=False,\n",
    "    drop_last=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.optim.lr_scheduler import MultiStepLR\n",
    "from torch import nn\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "gopt_model = GOPT(\n",
    "    embed_dim=32, num_heads=1, \n",
    "    depth=3, input_dim=83, \n",
    "    max_length=128, num_phone=62).to(device)\n",
    "\n",
    "trainables = [p for p in gopt_model.parameters() if p.requires_grad]\n",
    "\n",
    "lr = 3e-4\n",
    "optimizer = torch.optim.Adam(\n",
    "    trainables, lr, weight_decay=5e-7, betas=(0.95, 0.999))\n",
    "\n",
    "scheduler = MultiStepLR(\n",
    "    optimizer, list(range(10, 100, 5)), gamma=0.5, last_epoch=-1)\n",
    "\n",
    "loss_fn = nn.MSELoss()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "def valid_phn(audio_output, target):\n",
    "    valid_token_pred = []\n",
    "    valid_token_target = []\n",
    "    # audio_output = audio_output.squeeze(2)\n",
    "    for i in range(audio_output.shape[0]):\n",
    "        for j in range(audio_output.shape[1]):\n",
    "            # only count valid tokens, not padded tokens (represented by negative values)\n",
    "            if target[i, j] >= 0:\n",
    "                valid_token_pred.append(audio_output[i, j])\n",
    "                valid_token_target.append(target[i, j])\n",
    "    valid_token_target = np.array(valid_token_target)\n",
    "    valid_token_pred = np.array(valid_token_pred)\n",
    "\n",
    "    # valid_token_mse = np.mean((valid_token_target - valid_token_pred) ** 2)\n",
    "    valid_token_mse = np.mean(np.abs(valid_token_target - valid_token_pred))\n",
    "    corr = np.corrcoef(valid_token_pred, valid_token_target)[0, 1]\n",
    "    return valid_token_mse, corr\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 1875/1875 [00:10<00:00, 185.35it/s, loss_phn=0.198] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "### Validation result: MSE=0.29108473658561707 PCC=0.7001130661624079\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 1875/1875 [00:09<00:00, 190.50it/s, loss_phn=0.194] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "### Validation result: MSE=0.30746012926101685 PCC=0.716619169557578\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 1875/1875 [00:10<00:00, 184.71it/s, loss_phn=0.124] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "### Validation result: MSE=0.2788500189781189 PCC=0.7275677345583771\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 1875/1875 [00:09<00:00, 189.89it/s, loss_phn=0.152] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "### Validation result: MSE=0.2901957929134369 PCC=0.7363527593223207\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 1875/1875 [00:10<00:00, 181.26it/s, loss_phn=0.142] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "### Validation result: MSE=0.26718783378601074 PCC=0.7373961984593266\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 1875/1875 [00:09<00:00, 187.98it/s, loss_phn=0.31]  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "### Validation result: MSE=0.27253687381744385 PCC=0.7400577508304413\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 1875/1875 [00:09<00:00, 195.67it/s, loss_phn=0.179] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "### Validation result: MSE=0.2626534700393677 PCC=0.7413772353974766\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 1875/1875 [00:09<00:00, 190.75it/s, loss_phn=0.113] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "### Validation result: MSE=0.25720611214637756 PCC=0.7434466204989097\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 1875/1875 [00:09<00:00, 192.71it/s, loss_phn=0.191] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "### Validation result: MSE=0.28482505679130554 PCC=0.7416108548755624\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 1875/1875 [00:10<00:00, 183.55it/s, loss_phn=0.143] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "### Validation result: MSE=0.2724441587924957 PCC=0.7490480578058544\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 1875/1875 [00:09<00:00, 192.29it/s, loss_phn=0.1]   \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "### Validation result: MSE=0.2682347893714905 PCC=0.744101166549123\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 1875/1875 [00:09<00:00, 194.30it/s, loss_phn=0.0985]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "### Validation result: MSE=0.2625957429409027 PCC=0.7508961775155177\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 1875/1875 [00:09<00:00, 191.53it/s, loss_phn=0.348] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "### Validation result: MSE=0.25377243757247925 PCC=0.7468596312857673\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 1875/1875 [00:10<00:00, 184.90it/s, loss_phn=0.0874]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "### Validation result: MSE=0.25727730989456177 PCC=0.7437738951693265\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 1875/1875 [00:09<00:00, 191.19it/s, loss_phn=0.125] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "### Validation result: MSE=0.2582545578479767 PCC=0.7512051823926413\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 1875/1875 [00:09<00:00, 188.37it/s, loss_phn=0.104] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "### Validation result: MSE=0.2632337510585785 PCC=0.7464600171956045\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 1875/1875 [00:09<00:00, 191.15it/s, loss_phn=0.209] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "### Validation result: MSE=0.2567666172981262 PCC=0.7505230194654599\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 1875/1875 [00:09<00:00, 189.56it/s, loss_phn=0.0267]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "### Validation result: MSE=0.27048149704933167 PCC=0.7451561013824641\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 1875/1875 [00:10<00:00, 186.75it/s, loss_phn=0.078] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "### Validation result: MSE=0.27228450775146484 PCC=0.7485769393932062\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 1875/1875 [00:09<00:00, 192.54it/s, loss_phn=0.144] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "### Validation result: MSE=0.2605966627597809 PCC=0.7455377828079999\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 1875/1875 [00:10<00:00, 185.18it/s, loss_phn=0.115] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "### Validation result: MSE=0.27161967754364014 PCC=0.7482056721357718\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 1875/1875 [00:09<00:00, 193.88it/s, loss_phn=0.155] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "### Validation result: MSE=0.2610585391521454 PCC=0.7405667060887013\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 1875/1875 [00:08<00:00, 209.07it/s, loss_phn=0.136] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "### Validation result: MSE=0.25510427355766296 PCC=0.7440526742850676\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 1875/1875 [00:08<00:00, 210.44it/s, loss_phn=0.169] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "### Validation result: MSE=0.26209816336631775 PCC=0.7479798780182747\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 1875/1875 [00:09<00:00, 204.10it/s, loss_phn=0.0991]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "### Validation result: MSE=0.26780498027801514 PCC=0.7466108757719125\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 1875/1875 [00:08<00:00, 219.73it/s, loss_phn=0.147] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "### Validation result: MSE=0.27326980233192444 PCC=0.7431722748739634\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 1875/1875 [00:08<00:00, 215.50it/s, loss_phn=0.198] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "### Validation result: MSE=0.26220715045928955 PCC=0.7387126721722783\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 1875/1875 [00:08<00:00, 216.38it/s, loss_phn=0.0927]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "### Validation result: MSE=0.25596094131469727 PCC=0.738017315337226\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 1875/1875 [00:08<00:00, 219.12it/s, loss_phn=0.181] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "### Validation result: MSE=0.25277408957481384 PCC=0.743319320417549\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 1875/1875 [00:09<00:00, 207.56it/s, loss_phn=0.217] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "### Validation result: MSE=0.2622224688529968 PCC=0.7397613206856892\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 1875/1875 [00:09<00:00, 204.40it/s, loss_phn=0.0865]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "### Validation result: MSE=0.2561575472354889 PCC=0.7340736135024731\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 1875/1875 [00:08<00:00, 211.75it/s, loss_phn=0.224] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "### Validation result: MSE=0.2559139132499695 PCC=0.7338095860249196\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 1875/1875 [00:09<00:00, 204.05it/s, loss_phn=0.145] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "### Validation result: MSE=0.25950098037719727 PCC=0.7361036543310719\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 1875/1875 [00:09<00:00, 207.96it/s, loss_phn=0.125] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "### Validation result: MSE=0.2605656683444977 PCC=0.7385714745497297\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 1875/1875 [00:09<00:00, 193.97it/s, loss_phn=0.198] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "### Validation result: MSE=0.26970353722572327 PCC=0.7307985653401722\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 1875/1875 [00:09<00:00, 201.24it/s, loss_phn=0.175] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "### Validation result: MSE=0.2607308030128479 PCC=0.735962800751806\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 1875/1875 [00:08<00:00, 208.94it/s, loss_phn=0.164] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "### Validation result: MSE=0.264161080121994 PCC=0.7294233557068942\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 1875/1875 [00:08<00:00, 212.91it/s, loss_phn=0.187] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "### Validation result: MSE=0.2537757456302643 PCC=0.7333901913582335\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 1875/1875 [00:09<00:00, 199.76it/s, loss_phn=0.137] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "### Validation result: MSE=0.26516082882881165 PCC=0.7275677766496027\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 1875/1875 [00:08<00:00, 210.60it/s, loss_phn=0.149] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "### Validation result: MSE=0.2557547688484192 PCC=0.7309767963568082\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 1875/1875 [00:08<00:00, 213.48it/s, loss_phn=0.0587]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "### Validation result: MSE=0.2556030750274658 PCC=0.7302490511627804\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 1875/1875 [00:08<00:00, 211.31it/s, loss_phn=0.0959]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "### Validation result: MSE=0.27761566638946533 PCC=0.721733431062616\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 1875/1875 [00:08<00:00, 213.07it/s, loss_phn=0.109] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "### Validation result: MSE=0.26110532879829407 PCC=0.723056820165101\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 1875/1875 [00:09<00:00, 207.85it/s, loss_phn=0.077] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "### Validation result: MSE=0.2606257498264313 PCC=0.7211752607540315\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 1875/1875 [00:09<00:00, 205.34it/s, loss_phn=0.112] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "### Validation result: MSE=0.2634229063987732 PCC=0.7181631439785604\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 1875/1875 [00:09<00:00, 203.32it/s, loss_phn=0.0994]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "### Validation result: MSE=0.2595406770706177 PCC=0.7218853208800815\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 1875/1875 [00:09<00:00, 208.00it/s, loss_phn=0.1]    \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "### Validation result: MSE=0.2583596110343933 PCC=0.719185177641\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 1875/1875 [00:09<00:00, 208.27it/s, loss_phn=0.12]  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "### Validation result: MSE=0.25476333498954773 PCC=0.7216548879735138\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 1875/1875 [00:09<00:00, 201.15it/s, loss_phn=0.0915]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "### Validation result: MSE=0.26247966289520264 PCC=0.7223967059574722\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 1875/1875 [00:08<00:00, 213.86it/s, loss_phn=0.145] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "### Validation result: MSE=0.27141401171684265 PCC=0.7196600550855776\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "global_step = 0\n",
    "for epoch in range(50):\n",
    "    gopt_model.train()\n",
    "    train_tqdm = tqdm(trainloader, \"Training\")\n",
    "\n",
    "    for batch in train_tqdm:\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        features = batch[\"features\"].to(device)\n",
    "        phones = batch[\"phones\"].to(device)\n",
    "        phone_labels = batch[\"phone_scores\"].to(device)\n",
    "\n",
    "        # warm_up_step = 100\n",
    "        # if global_step <= warm_up_step and global_step % 5 == 0:\n",
    "        #     warm_lr = (global_step / warm_up_step) * lr\n",
    "        #     for param_group in optimizer.param_groups:\n",
    "        #         param_group['lr'] = warm_lr\n",
    "\n",
    "        utterance_preds, phone_preds, word_preds = gopt_model(x=features.float(), phn=phones.long())\n",
    "        \n",
    "        mask = phone_labels >=0\n",
    "        phone_preds = phone_preds.squeeze(2)\n",
    "        phone_preds = phone_preds * mask\n",
    "        phone_labels = phone_labels * mask\n",
    "        \n",
    "        loss_phn = loss_fn(phone_preds, phone_labels)\n",
    "        loss_phn = loss_phn * (mask.shape[0] * mask.shape[1]) / torch.sum(mask)\n",
    "        \n",
    "        loss_phn.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # if global_step > warm_up_step:\n",
    "        #     scheduler.step()\n",
    "        \n",
    "        global_step += 1\n",
    "\n",
    "        train_tqdm.set_postfix(loss_phn=loss_phn.item())\n",
    "    \n",
    "    A_phn, A_phn_target = [], []\n",
    "    for batch in testloader:\n",
    "        features = batch[\"features\"].to(device)\n",
    "        phones = batch[\"phones\"].to(device)\n",
    "        phone_labels = batch[\"phone_scores\"].to(device)\n",
    "        \n",
    "        utterance_preds, phone_preds, word_preds = gopt_model(x=features.float(), phn=phones.long())\n",
    "        \n",
    "        phone_preds = phone_preds.detach().cpu()\n",
    "        phone_labels = phone_labels.detach().cpu()\n",
    "        \n",
    "        A_phn.append(phone_preds[:, :, 0])\n",
    "        A_phn_target.append(phone_labels)\n",
    "        \n",
    "    A_phn, A_phn_target  = torch.vstack(A_phn), torch.vstack(A_phn_target)\n",
    "    phn_mse, phn_corr = valid_phn(A_phn, A_phn_target)\n",
    "    print(f\"### Validation result: MSE={phn_mse} PCC={phn_corr}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ps",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.17"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
